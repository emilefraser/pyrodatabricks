{"cells":[{"cell_type":"markdown","source":["Functions available from **DataLakeHelperFunctionsNotebook**\n\n|Function|Purpose|\n|--|---|\n|mount_lake_container|Takes a container name and mounts it to Databricks. Prints out the name of the mount point. |"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"15c404f9-91b1-4d65-ab5a-468d3bb044f9"}}},{"cell_type":"code","source":["def mount_lake_container(pAdlsContainerName):\n  \n    \"\"\"\n    mount_lake_container: Takes a container name and mounts it to Databricks. Prints out the name of the mount point. \n    Key Vault SecretScopeName = \"DianGRAndDKeyVault\"\n    Key Vault Secret with Data Lake Name: dianrandddatalake-storageaccountname\n    Key Vault Secret with ClientID = \"RandD-ServicePrinciple-ApplicationID\"\n    Key Vault Secret with ClientSecret = \"RandD-ServicePrinciple-Password\"\n    Key Vault Secret with TenantID = \"RandD-ServicePrinciple-TenantID\"\n    \"\"\"\n    # Python code to mount and access Azure Data Lake Storage Gen2 Account from Azure Databricks with Service Principal and OAuth\n\n    # KeyVault Secret Scope Name\n    VarSecretScopeName = \"DianGRAndDKeyVault\" ##this would be a fixed name we would have a standard for. Ideally there is only one secret scope for automated notebooks\n\n    # Define the variables used for creating connection strings - Data Lake Related\n    varAdlsAccountName = dbutils.secrets.get(scope=VarSecretScopeName,key=\"dianrandddatalake-storageaccountname\") # e.g. \"dianrandddatalake\" --the storage account name itself\n    varAdlsContainerName = pAdlsContainerName # e.g. rawdata, bronze, silver, gold, platinum etc.\n    varMountPoint = \"/mnt/datalake_\" + varAdlsContainerName #fixed since we already parameterised the container name. Ensures there is a standard in mount point naming\n\n    # Define the variables that have the names of the secrets in key vault that store the sensitive information we need for the conenction via Service Principle Auth\n    VarSecretClientID = \"RandD-ServicePrinciple-ApplicationID\" #Name of the generic key vault secret contianing the Service Principle Name.\n    VarSecretClientSecret = \"RandD-ServicePrinciple-Password\" #Name of the generic key vault secret contianing the Service Principle Password. \n    VarSecretTenantID = \"RandD-ServicePrinciple-TenantID\" #Name of the generic key vault secret contianing the Tenant ID.\n\n    # Get the actual secrets from key vault for the service principle\n    varApplicationId = dbutils.secrets.get(scope=VarSecretScopeName, key=VarSecretClientID) # Application (Client) ID\n    varAuthenticationKey = dbutils.secrets.get(scope=VarSecretScopeName, key=VarSecretClientSecret) # Application (Client) Secret Key\n    varTenantId = dbutils.secrets.get(scope=VarSecretScopeName, key=VarSecretTenantID) # Directory (Tenant) ID\n\n    # Using the secrets above, generate the URL to the storage account and the authentication endpoint for OAuth\n    varEndpoint = \"https://login.microsoftonline.com/\" + varTenantId + \"/oauth2/token\" #Fixed URL for the endpoint\n    varSource = \"abfss://\" + varAdlsContainerName + \"@\" + varAdlsAccountName + \".dfs.core.windows.net/\"\n\n    # Connecting using Service Principal secrets and OAuth\n    varConfigs = {\"fs.azure.account.auth.type\": \"OAuth\", #standard\n               \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\", #standard\n               \"fs.azure.account.oauth2.client.id\": varApplicationId,\n               \"fs.azure.account.oauth2.client.secret\": varAuthenticationKey,\n               \"fs.azure.account.oauth2.client.endpoint\": varEndpoint}\n\n    # Mount ADLS Storage to DBFS only if the directory is not already mounted\n    # Mount is generated as a list of all mount points available already via dbutils.fs.mounts()\n    # Then it checks the list for the new mount point we are trying to generate.\n    if not any(mount.mountPoint == varMountPoint for mount in dbutils.fs.mounts()): \n      dbutils.fs.mount(\n        source = varSource,\n        mount_point = varMountPoint,\n        extra_configs = varConfigs)\n\n    # print the mount point used for troubleshooting\n    print(\"Mount Point: \" + varMountPoint)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b728844a-9487-4594-88dd-9d0515a7fd40"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"DataLakeHelperFunctionsNotebook","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4,"widgetLayout":[]},"language":"python","widgets":{},"notebookOrigID":3994415014486397}},"nbformat":4,"nbformat_minor":0}
