# Welcome to the Build A Thing series

<img src="https://github.com/dennyglee/tech-talks/blob/master/courses/build-a-thing/images/build-a-thing-splash.png" width="1000">

Join us for the brand new tech talk series "Simon and Denny - Build A Thing!" (as part of the [Data + AI Onlne Meetup](https://www.meetup.com/data-ai-online/))where across a series of tech talks, we will build a data platform from ingestion to ETL to analytics and data science using the Azure Databricks platform. With our background in SQL Server and BI to Apache Spark and Delta Lake - we want to show you how to build your own lakehouse.

We would like this session to be interactive so come prepared to ask questions all throughout the session - the very first one will focus on the ingestion of data. Our conversations together will also guide what we will discuss in the next session! Be prepared for another geeky, trans-Atlantic event from two data nerds.


## Part 1: Data Ingestion
For the first session, we will discuss the configurations as well as how to jump start with data ingestion with Auto Loader.  Some great resources include:

* [Quickstart: Run a Spark job on Azure Databricks Workspace using the Azure portal](https://docs.microsoft.com/en-us/azure/databricks/scenarios/quickstart-create-databricks-workspace-portal?tabs=azure-portal)

* [Create an Azure storage account](https://docs.microsoft.com/en-us/azure/storage/common/storage-account-create?tabs=azure-portal): Recommend using [Azure Data Lake Storage Gen2](https://docs.microsoft.com/en-us/azure/storage/blobs/data-lake-storage-introduction)

* [Azure Key Vault](https://docs.microsoft.com/en-us/azure/key-vault/general/overview)

* [Tutorial: Run a job with an Azure service principal](https://docs.microsoft.com/en-us/azure/databricks/tutorials/run-jobs-with-service-principals)



