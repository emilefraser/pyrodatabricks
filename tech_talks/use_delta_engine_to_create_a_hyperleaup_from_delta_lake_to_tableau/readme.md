## Use Delta Engine to create a Hyperleaup from Delta Lake to Tableau

2020-10-20 | [Watch the video](https://www.youtube.com/watch?v=KS20Ybft3ok) | This folder contains the notebooks used in this tutorial.


Welcome to the Data Collab Lab with Franco and Denny! This online meetup series brings together various data experts and we collaborate together to (hopefully) solve the problem!

For this session, we will discuss: [Use Delta Engine to create a Hyperleaup from Delta Lake to Tableau](https://www.youtube.com/watch?v=KS20Ybft3ok)

Are you struggling with performance on your Tableau experience in the cloud?  Do you use Tableau Server to Extract data from Delta Lake?  Want to learn how you can create a hyperleaup from your Delta Lake to Tableau that will decrease latency to insights?  Join us as we collaborate with Will Girten and Shoam Bhatt, and figure out what exactly a hyperleaup is!  


### Guests
Will Girten is a Sr. RSA at Databricks. He's helped some of the largest federal customers at Databricks build modern, enterprise Delta Lakes in the cloud. He specializes in building efficient and reliable ETL pipelines for fast data engineering and BI workloads.

Soham Bhatt is a Senior Solutions Architect at Databricks based out of Seattle, WA. He is passionate about helping his customers in their journeys to build modern Data Lakes for Advanced Analytics and ML/AI. Before Databricks he worked at Toyota Motors on building their next generation Big Data Platform. Prior to that his background was in building Enterprise Data Warehouses for Fortune 100 companies with Kimball methodologies and now he loves guiding his customers with best practices as they convert those EDWs into modern Data Engineering Platforms in AWS and Azure.

### Hosts
Franco Patano is a Senior Solutions Architect at Databricks, where he brings over 10 years of industry experience in data engineering and analytics. He has architected, managed, and analyzed data applications both big and small, with open source and proprietary software, utilizing SQL, Python, Scala, Java, and Apache Spark, as well as experimenting with data science. Prior to Databricks, Franco worked as a Data Architect and Analyst in the Commercial Real Estate, Banking, and Education industries for organizations large and small.

Denny Lee is a developer advocate at Databricks, where he works on Delta Lake, Apache Spark, Data Sciences, and Healthcare Life Sciences. He has previously built enterprise DW/BI and big data systems at Microsoft including Azure Cosmos DB, Project Isotope (HDInsight), and SQL Server as well as the Senior Director of Data Sciences Engineering at SAP Concur. Denny holds a Masters in Biomedical Informatics from Oregon Health Sciences University.
