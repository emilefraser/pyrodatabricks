{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How Delta Lake Supercharges Data Lakes\n",
    "\n",
    "Delta Lake’s transaction log brings high reliability, performance, and ACID compliant transactions to data lakes. But exactly how does it accomplish this?\n",
    "Working through concrete examples, we will take a close look at how the transaction logs are managed and leveraged by Delta to supercharge data lakes.\n",
    "\n",
    "This tutorial notebook was developed using open source Delta Lake in an open source environment.\n",
    "\n",
    "### Environment used to develop and run this notebook\n",
    "* [Centos 7.8](https://www.centos.org/download/)\n",
    "* [Spark 3.0](http://spark.apache.org/docs/latest/)\n",
    "* [Delta Lake 0.7.0](https://github.com/delta-io/delta/releases)\n",
    "* [Scala 2.12](https://www.scala-lang.org/download/2.12.8.html)\n",
    "* [Jupyterlab 2.1.5](https://jupyterlab.readthedocs.io/en/stable/getting_started/installation.html)\n",
    "\n",
    "### Installing Delta Lake\n",
    "* [Download 0.7.0 jar file](https://mvnrepository.com/artifact/io.delta/delta-core_2.12/0.7.0)\n",
    "* Move jar file to $SPARK_HOME/jars\n",
    "* More Details here: [Setting up Apache Spark with Delta](https://docs.delta.io/latest/quick-start.html#set-up-apache-spark-with-delta-lake)\n",
    "\n",
    "### Source Data for this notebook\n",
    "\n",
    "The data used in this tutorial is a modified version of the public data from [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/datasets/Online+Retail#). This dataset contains transactional data from a UK online retailer and it spans January 12, 2010 to September 12, 2011. For a full view of the data please view the data dictionary available [here](http://archive.ics.uci.edu/ml/datasets/Online+Retail#)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<img src=\"https://docs.delta.io/latest/_static/delta-lake-logo.png\" width=300/>  \n",
    "\n",
    "An open-source storage format that brings ACID transactions to Apache Spark™ and big data workloads.\n",
    "\n",
    "* **Open format**: Stored as Parquet format in blob storage.\n",
    "* **ACID Transactions**: Ensures data integrity and read consistency with complex, concurrent data pipelines.\n",
    "* **Schema Enforcement and Evolution**: Ensures data cleanliness by blocking writes with unexpected.\n",
    "* **Audit History**: History of all the operations that happened in the table.\n",
    "* **Time Travel**: Query previous versions of the table by time or version number.\n",
    "* **Deletes and upserts**: Supports deleting and upserting into tables with programmatic APIs.\n",
    "* **Scalable Metadata management**: Able to handle millions of files are scaling the metadata operations with Spark.\n",
    "* **Unified Batch and Streaming Source and Sink**: A table in Delta Lake is both a batch table, as well as a streaming source and sink. Streaming data ingest, batch historic backfill, and interactive queries all just work out of the box.\n",
    "\n",
    "<img src=\"https://www.evernote.com/l/AAF4VIILJtFNZLuvZjGGhZTr2H6Z0wh6rOYB/image.png\" width=800px align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup, Helpers, Config & APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Classes\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import sum, expr, rand, when, count, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Spark session & configure it for Delta Lake version 0.7.0\n",
    "\n",
    "# Load delta library - .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:0.7.0\")\n",
    "# Enable sql (Delta Lake specific) support within Apache Spark - .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "# Enable integration with Catalog APIs (since 3.0) - .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "spark = SparkSession.builder.appName(\"DeltaLake Transaction Logs\") \\\n",
    "    .master(\"local[4]\") \\\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:0.7.0\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Main class for programmatically intereacting with Delta Tables.\n",
    "from delta.tables import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set configurations for our Spark Session\n",
    "# Adjust to your environment, e.g # cores on cluster\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 4)\n",
    "spark.conf.set(\"spark.default.parallelism\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load helper functions\n",
    "\n",
    "%run Helpers.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Data File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted path /home/spark/data/delta/online_retail_data\n",
      "Deleted path /home/spark/data/parquet/online_retail_data\n"
     ]
    }
   ],
   "source": [
    "# Source data\n",
    "# Change paths to match your environment!\n",
    "\n",
    "inputPath    = \"/home/spark/data/source/\"\n",
    "sourceData   = inputPath + \"online-retail-dataset.csv\"\n",
    "\n",
    "# Base location for all saved data\n",
    "basePath     = \"/home/spark/data\" \n",
    "\n",
    "# Path for Parquet formatted data\n",
    "parquetPath  = basePath + \"/parquet/online_retail_data\"\n",
    "\n",
    "# Path for Delta formatted data\n",
    "deltaPath    = basePath + \"/delta/online_retail_data\"\n",
    "deltaLogPath = deltaPath + \"/_delta_log\"\n",
    "\n",
    "# Clean up from last run.\n",
    "! rm -Rf $deltaPath 2>/dev/null\n",
    "print(\"Deleted path \" + deltaPath)\n",
    "\n",
    "! rm -Rf $parquetPath 2>/dev/null\n",
    "print(\"Deleted path \" + parquetPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and Stage Source Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Dataset is present.\n",
      "\n",
      "File [/home/spark/data/source/online-retail-dataset.csv] is ['43'] MB in size.\n"
     ]
    }
   ],
   "source": [
    "# Data sourced from \"Spark - The Definitive Guide\", located at: https://github.com/databricks/Spark-The-Definitive-Guide\n",
    "# Data origin: http://archive.ics.uci.edu/ml/datasets/Online+Retail\n",
    "import os.path\n",
    "\n",
    "file_exists = os.path.isfile(f'{sourceData}')\n",
    " \n",
    "if not file_exists:\n",
    "    print(\"-> Downloading dataset.\")\n",
    "    os.system(f'curl https://raw.githubusercontent.com/databricks/Spark-The-Definitive-Guide/master/data/retail-data/all/online-retail-dataset.csv -o {sourceData}')\n",
    "    file_exists = os.path.isfile(f'{sourceData}')\n",
    "    \n",
    "if file_exists:\n",
    "    print(\"-> Dataset is present.\\n\")\n",
    "    \n",
    "    fileSize = ! du -m \"$sourceData\" | cut -f1 # Posix compliant\n",
    "    print(f\"File [{sourceData}] is {fileSize} MB in size.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Schema for Source Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InvoiceNo,StockCode,Description,Quantity,InvoiceDate,UnitPrice,CustomerID,Country\n",
      "536365,85123A,WHITE HANGING HEART T-LIGHT HOLDER,6,12/1/2010 8:26,2.55,17850,United Kingdom\n",
      "536365,71053,WHITE METAL LANTERN,6,12/1/2010 8:26,3.39,17850,United Kingdom\n",
      "536365,84406B,CREAM CUPID HEARTS COAT HANGER,8,12/1/2010 8:26,2.75,17850,United Kingdom\n",
      "536365,84029G,KNITTED UNION FLAG HOT WATER BOTTLE,6,12/1/2010 8:26,3.39,17850,United Kingdom\n"
     ]
    }
   ],
   "source": [
    "# Let's take a peek at the data as a text file\n",
    "! head -n 5 $sourceData 2>/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide schema for source data\n",
    "# Schema source: http://archive.ics.uci.edu/ml/datasets/Online+Retail#\n",
    "\n",
    "# SQL DDL method\n",
    "schemaDDL = \"\"\"InvoiceNo Integer, StockCode String, Description String, Quantity Integer, \n",
    "               InvoiceDate String, UnitPrice Double, CustomerID Integer, Country String \"\"\"\n",
    "\n",
    "\n",
    "# You could also use the StructType method.\n",
    "# Libraries needed to define schemas\n",
    "# from pyspark.sql.types import StructType, StructField, DoubleType, IntegerType, StringType\n",
    "\n",
    "#inputSchema = StructType([\n",
    "#  StructField(\"InvoiceNo\", IntegerType(), True),\n",
    "#  StructField(\"StockCode\", StringType(), True),\n",
    "#  StructField(\"Description\", StringType(), True),\n",
    "#  StructField(\"Quantity\", IntegerType(), True),\n",
    "#  StructField(\"InvoiceDate\", StringType(), True),\n",
    "#  StructField(\"UnitPrice\", DoubleType(), True),\n",
    "#  StructField(\"CustomerID\", IntegerType(), True),\n",
    "#  StructField(\"Country\", StringType(), True)\n",
    "#])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Count: 541909 Partition Count: 4\n"
     ]
    }
   ],
   "source": [
    "# Create retail sales data dataframe\n",
    "\n",
    "rawSalesDataDF = (\n",
    "    spark.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\",\"true\")\n",
    "    .schema(schemaDDL)\n",
    "    .load(sourceData)\n",
    ")\n",
    "\n",
    "# Count rows and partitions\n",
    "rowCount = rawSalesDataDF.count() \n",
    "partCount = rawSalesDataDF.rdd.getNumPartitions()\n",
    "\n",
    "print(f'Row Count: {rowCount} Partition Count: {partCount}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with null values\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "|InvoiceNo|StockCode|Description|Quantity|InvoiceDate|UnitPrice|CustomerID|Country|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "|     9291|        0|       1454|       0|          0|        0|    135080|      0|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Identify columns with null values\n",
    "\n",
    "print(\"Columns with null values\")\n",
    "rawSalesDataDF.select([count(when(col(c).isNull(), c)).alias(c) for c in rawSalesDataDF.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null values\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "|InvoiceNo|StockCode|Description|Quantity|InvoiceDate|UnitPrice|CustomerID|Country|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "|        0|        0|          0|       0|          0|        0|         0|      0|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "\n",
      " RowsRemoved: 143985\n",
      " Final Row Count: 397924\n"
     ]
    }
   ],
   "source": [
    "# Remove rows where important columns are null. In our case: InvoiceNo and CustomerID\n",
    "\n",
    "cleanSalesDataDF = rawSalesDataDF.where(col(\"InvoiceNo\").isNotNull() & col(\"CustomerID\").isNotNull())\n",
    "cleanSalesDataCount = cleanSalesDataDF.count()\n",
    "# POO cleanSalesDataDF = cleanSalesDataDF.where(col(\"CustomerID\").isNotNull())\n",
    "\n",
    "# All rows with null values should be gone\n",
    "print(\"null values\")\n",
    "cleanSalesDataDF.select([count(when(col(c).isNull(), c)).alias(c) for c in rawSalesDataDF.columns]).show()\n",
    "\n",
    "print(f' RowsRemoved: {rowCount-cleanSalesDataCount}\\n Final Row Count: {cleanSalesDataCount}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Count: 99226 Partition Count: 4\n"
     ]
    }
   ],
   "source": [
    "# Define new dataframe based on cleansed data but only use a subset of the data to make things run faster\n",
    "\n",
    "# Random sample of 25%, with seed and without replacement\n",
    "retailSalesData1 = cleanSalesDataDF.sample(withReplacement=False, fraction=.25, seed=75)\n",
    "\n",
    "# Count rows and partitions\n",
    "rowCount = retailSalesData1.count() \n",
    "partCount = retailSalesData1.rdd.getNumPartitions()\n",
    "\n",
    "print(f'Row Count: {rowCount} Partition Count: {partCount}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------------------------------+--------+--------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|Description                        |Quantity|InvoiceDate   |UnitPrice|CustomerID|Country       |\n",
      "+---------+---------+-----------------------------------+--------+--------------+---------+----------+--------------+\n",
      "|536365   |84029G   |KNITTED UNION FLAG HOT WATER BOTTLE|6       |12/1/2010 8:26|3.39     |17850     |United Kingdom|\n",
      "|536365   |84029E   |RED WOOLLY HOTTIE WHITE HEART.     |6       |12/1/2010 8:26|3.39     |17850     |United Kingdom|\n",
      "|536365   |21730    |GLASS STAR FROSTED T-LIGHT HOLDER  |6       |12/1/2010 8:26|4.25     |17850     |United Kingdom|\n",
      "+---------+---------+-----------------------------------+--------+--------------+---------+----------+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Peek at the dataframe\n",
    "\n",
    "retailSalesData1.show(3, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HIVE Metastore Database Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "|deltademo|\n",
      "| louis_db|\n",
      "+---------+\n",
      "\n",
      "+------------------+\n",
      "|current_database()|\n",
      "+------------------+\n",
      "|         deltademo|\n",
      "+------------------+\n",
      "\n",
      "+-------------------------+----------------------------------------------------------------------------------------+\n",
      "|database_description_item|database_description_value                                                              |\n",
      "+-------------------------+----------------------------------------------------------------------------------------+\n",
      "|Database Name            |deltademo                                                                               |\n",
      "|Comment                  |                                                                                        |\n",
      "|Location                 |file:/home/spark/projects/spark3-projects/spark3-playground/spark-warehouse/deltademo.db|\n",
      "|Owner                    |spark                                                                                   |\n",
      "+-------------------------+----------------------------------------------------------------------------------------+\n",
      "\n",
      "+--------+---------+-----------+\n",
      "|database|tableName|isTemporary|\n",
      "+--------+---------+-----------+\n",
      "+--------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create database to hold demo objects\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS deltademo\")\n",
    "spark.sql(\"SHOW DATABASES\").show()\n",
    "\n",
    "# Current DB should be deltademo\n",
    "spark.sql(\"USE deltademo\")\n",
    "spark.sql(\"SELECT CURRENT_DATABASE()\").show()\n",
    "spark.sql(\"DESCRIBE DATABASE deltademo\").show(truncate = False)\n",
    "\n",
    "# Clean-up from last run\n",
    "spark.sql(\"DROP TABLE IF EXISTS SalesParquetFormat\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS SalesDeltaFormat\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS tbl_CheckpointFile\")\n",
    "spark.sql(\"SHOW TABLES\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Parquet Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data as a table in Parquet format\n",
    "\n",
    "retailSalesData1.write.saveAsTable('SalesParquetFormat', format='parquet', mode='overwrite',path=parquetPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='salesparquetformat', database='deltademo', description=None, tableType='EXTERNAL', isTemporary=False)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's peek into the catalog and verify that our table was created\n",
    "\n",
    "spark.catalog.listTables()\n",
    "\n",
    "# SQL method - not as informative\n",
    "# spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312KB    2020-08-26 10:12:29  part-00001-7c5ca58b-c85f-4fc7-826b-35886eebec8d-c000.snappy.parquet\n",
      "282KB    2020-08-26 10:12:29  part-00000-7c5ca58b-c85f-4fc7-826b-35886eebec8d-c000.snappy.parquet\n",
      "195KB    2020-08-26 10:12:29  part-00003-7c5ca58b-c85f-4fc7-826b-35886eebec8d-c000.snappy.parquet\n",
      "314KB    2020-08-26 10:12:29  part-00002-7c5ca58b-c85f-4fc7-826b-35886eebec8d-c000.snappy.parquet\n",
      "\n",
      "Number of file/s: 4 | Total size: 1.2M\n"
     ]
    }
   ],
   "source": [
    "# Files and size on disk\n",
    "\n",
    "files_in_dir(parquetPath, \"parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+--------------------------------------------------------------+-------+\n",
      "|col_name                    |data_type                                                     |comment|\n",
      "+----------------------------+--------------------------------------------------------------+-------+\n",
      "|InvoiceNo                   |int                                                           |null   |\n",
      "|StockCode                   |string                                                        |null   |\n",
      "|Description                 |string                                                        |null   |\n",
      "|Quantity                    |int                                                           |null   |\n",
      "|InvoiceDate                 |string                                                        |null   |\n",
      "|UnitPrice                   |double                                                        |null   |\n",
      "|CustomerID                  |int                                                           |null   |\n",
      "|Country                     |string                                                        |null   |\n",
      "|                            |                                                              |       |\n",
      "|# Detailed Table Information|                                                              |       |\n",
      "|Database                    |deltademo                                                     |       |\n",
      "|Table                       |salesparquetformat                                            |       |\n",
      "|Owner                       |spark                                                         |       |\n",
      "|Created Time                |Wed Aug 26 10:12:30 EDT 2020                                  |       |\n",
      "|Last Access                 |UNKNOWN                                                       |       |\n",
      "|Created By                  |Spark 3.0.0                                                   |       |\n",
      "|Type                        |EXTERNAL                                                      |       |\n",
      "|Provider                    |parquet                                                       |       |\n",
      "|Statistics                  |1129731 bytes                                                 |       |\n",
      "|Location                    |file:/home/spark/data/parquet/online_retail_data              |       |\n",
      "|Serde Library               |org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe   |       |\n",
      "|InputFormat                 |org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat |       |\n",
      "|OutputFormat                |org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat|       |\n",
      "+----------------------------+--------------------------------------------------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"describe extended SalesParquetFormat\").show(100,truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+----------------------------+--------+---------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|Description                 |Quantity|InvoiceDate    |UnitPrice|CustomerID|Country       |\n",
      "+---------+---------+----------------------------+--------+---------------+---------+----------+--------------+\n",
      "|563016   |21497    |FANCY FONTS BIRTHDAY WRAP   |25      |8/11/2011 12:44|0.42     |15358     |United Kingdom|\n",
      "|563016   |22993    |SET OF 4 PANTRY JELLY MOULDS|12      |8/11/2011 12:44|1.25     |15358     |United Kingdom|\n",
      "|563016   |22961    |JAM MAKING SET PRINTED      |12      |8/11/2011 12:44|1.45     |15358     |United Kingdom|\n",
      "+---------+---------+----------------------------+--------+---------------+---------+----------+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use Spark SQL to query the newly created table\n",
    "\n",
    "spark.sql(\"SELECT * FROM SalesParquetFormat;\").show(3, truncate = False)\n",
    "\n",
    "# You can directly query the directory too.\n",
    "# spark.sql(f\"SELECT * FROM parquet.`{parquetPath}` limit 5 \").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add one row of data to the table\n",
    "# Parquet being immutable necessitates the creation of an additional Parquet file\n",
    "\n",
    "spark.sql(\"\"\" \n",
    "             INSERT INTO SalesParquetFormat\n",
    "              VALUES(963316, 2291, \"WORLD'S BEST JAM MAKING SET\", 5, \"08/13/2011 07:58\", 1.45, 15358, \"United Kingdom\")\n",
    "          \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312KB    2020-08-26 10:12:29  part-00001-7c5ca58b-c85f-4fc7-826b-35886eebec8d-c000.snappy.parquet\n",
      "282KB    2020-08-26 10:12:29  part-00000-7c5ca58b-c85f-4fc7-826b-35886eebec8d-c000.snappy.parquet\n",
      "195KB    2020-08-26 10:12:29  part-00003-7c5ca58b-c85f-4fc7-826b-35886eebec8d-c000.snappy.parquet\n",
      "314KB    2020-08-26 10:12:29  part-00002-7c5ca58b-c85f-4fc7-826b-35886eebec8d-c000.snappy.parquet\n",
      "2KB      2020-08-26 10:12:46  part-00000-598a98d4-a17f-4545-852e-85489289f836-c000.snappy.parquet\n",
      "\n",
      "Number of file/s: 5 | Total size: 1.2M\n"
     ]
    }
   ],
   "source": [
    "files_in_dir(parquetPath, \"parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have a peek at the new file\n",
    "\n",
    "# spark.read.load(f\"{parquetPath}/part-00000-806d3f4d-6f4e-4d04-a464-f08a1cda3b2f-c000.snappy.parquet\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Above we saw how to create a table structure using Parquet as the underlying data file format.<br>\n",
    "- Using sql we were able to query the table and even insert new data using sql.<br>\n",
    "- However, no history was kept of these operations.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Delta Lake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://files.training.databricks.com/images/adbcore/AAFxQkg_SzRC06GvVeatDBnNbDL7wUUgCg4B.png\" alt=\"Delta Lake\" width=\"600\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+----------------------------+--------+---------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|Description                 |Quantity|InvoiceDate    |UnitPrice|CustomerID|Country       |\n",
      "+---------+---------+----------------------------+--------+---------------+---------+----------+--------------+\n",
      "|563016   |21497    |FANCY FONTS BIRTHDAY WRAP   |25      |8/11/2011 12:44|0.42     |15358     |United Kingdom|\n",
      "|563016   |22993    |SET OF 4 PANTRY JELLY MOULDS|12      |8/11/2011 12:44|1.25     |15358     |United Kingdom|\n",
      "|563016   |22961    |JAM MAKING SET PRINTED      |12      |8/11/2011 12:44|1.45     |15358     |United Kingdom|\n",
      "+---------+---------+----------------------------+--------+---------------+---------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save retailSalesData1 to Delta\n",
    "\n",
    "retailSalesData1.write.mode(\"overwrite\").format(\"delta\").save(deltaPath)\n",
    "\n",
    "# Query delta directory directly\n",
    "spark.sql(f\"SELECT * FROM delta.`{deltaPath}` limit 3 \").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variable for a path based Delta table\n",
    "\n",
    "deltaTable = DeltaTable.forPath(spark, deltaPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### HISTORY ########\n",
      "+---+-------------------+---------+--------------------------------------+------------------------------------------------------------------+\n",
      "|ver|timestamp          |operation|operationParameters                   |operationMetrics                                                  |\n",
      "+---+-------------------+---------+--------------------------------------+------------------------------------------------------------------+\n",
      "|0  |2020-08-26 10:13:04|WRITE    |[mode -> Overwrite, partitionBy -> []]|[numFiles -> 4, numOutputBytes -> 1129731, numOutputRows -> 99226]|\n",
      "+---+-------------------+---------+--------------------------------------+------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"####### HISTORY ########\")\n",
    "\n",
    "# Observe history of actions taken on a Delta table\n",
    "history = deltaTable.history().select('version','timestamp','operation', 'operationParameters', \\\n",
    "                                      'operationMetrics') \\\n",
    "                              .withColumnRenamed(\"version\", \"ver\")\n",
    "\n",
    "history.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1.1M\n",
      "drwxrwxr-x. 2 spark spark   39 Aug 26 10:13 _delta_log\n",
      "-rw-r--r--. 1 spark spark 282K Aug 26 10:13 part-00000-30f975b9-52a0-4eb4-b72e-1ce6669d9576-c000.snappy.parquet\n",
      "-rw-r--r--. 1 spark spark 313K Aug 26 10:13 part-00001-58b422df-e828-45a4-b95c-ac2f62ee2dc7-c000.snappy.parquet\n",
      "-rw-r--r--. 1 spark spark 315K Aug 26 10:13 part-00002-25235bcc-3dc3-4a62-b354-10ca68c42a83-c000.snappy.parquet\n",
      "-rw-r--r--. 1 spark spark 196K Aug 26 10:13 part-00003-e1c13592-efaf-4ca7-9a0f-25484dccc18d-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "# files and size on disk\n",
    "# Notice the sub-directory \"_delta_log\"\n",
    "\n",
    "! ls -thl $deltaPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2KB      2020-08-26 10:13:04  00000000000000000000.json\n",
      "\n",
      "Number of file/s: 1 | Total size: 4.0K\n"
     ]
    }
   ],
   "source": [
    "# # files and size on disk\n",
    "# We can see that parquet files were added but now there is a trx log\n",
    "\n",
    "files_in_dir(deltaLogPath, \"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(add=None, commitInfo=Row(isBlindAppend=False, operation='WRITE', operationMetrics=Row(numFiles='4', numOutputBytes='1129731', numOutputRows='99226'), operationParameters=Row(mode='Overwrite', partitionBy='[]'), timestamp=1598451184123), metaData=None, protocol=None),\n",
       " Row(add=None, commitInfo=None, metaData=None, protocol=Row(minReaderVersion=1, minWriterVersion=2)),\n",
       " Row(add=None, commitInfo=None, metaData=Row(createdTime=1598451182505, format=Row(provider='parquet'), id='4126e7fa-86b6-4189-b565-79b85f699224', partitionColumns=[], schemaString='{\"type\":\"struct\",\"fields\":[{\"name\":\"InvoiceNo\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"StockCode\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"Description\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"Quantity\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"InvoiceDate\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"UnitPrice\",\"type\":\"double\",\"nullable\":true,\"metadata\":{}},{\"name\":\"CustomerID\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"Country\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}'), protocol=None),\n",
       " Row(add=Row(dataChange=True, modificationTime=1598451183000, path='part-00000-30f975b9-52a0-4eb4-b72e-1ce6669d9576-c000.snappy.parquet', size=288465), commitInfo=None, metaData=None, protocol=None),\n",
       " Row(add=Row(dataChange=True, modificationTime=1598451183000, path='part-00001-58b422df-e828-45a4-b95c-ac2f62ee2dc7-c000.snappy.parquet', size=319754), commitInfo=None, metaData=None, protocol=None),\n",
       " Row(add=Row(dataChange=True, modificationTime=1598451183000, path='part-00002-25235bcc-3dc3-4a62-b354-10ca68c42a83-c000.snappy.parquet', size=321712), commitInfo=None, metaData=None, protocol=None),\n",
       " Row(add=Row(dataChange=True, modificationTime=1598451183000, path='part-00003-e1c13592-efaf-4ca7-9a0f-25484dccc18d-c000.snappy.parquet', size=199800), commitInfo=None, metaData=None, protocol=None)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's have a peek inside the trx log\n",
    "\n",
    "spark.read.format(\"json\").load(deltaLogPath + \"/00000000000000000000.json\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99149"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataframe with fraction of original data.\n",
    "# Random sample of 25%, with seed and without replacement\n",
    "\n",
    "retailSalesData2 = cleanSalesDataDF.sample(withReplacement=False, fraction=.25, seed=31)\n",
    "retailSalesData2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to our Delta Lake table by appending retailSalesData2\n",
    "\n",
    "retailSalesData2.write.mode(\"append\").format(\"delta\").save(deltaPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### HISTORY ########\n",
      "+---+-------------------+---------+--------------------------------------+------------------------------------------------------------------+\n",
      "|ver|timestamp          |operation|operationParameters                   |operationMetrics                                                  |\n",
      "+---+-------------------+---------+--------------------------------------+------------------------------------------------------------------+\n",
      "|1  |2020-08-26 10:14:14|WRITE    |[mode -> Append, partitionBy -> []]   |[numFiles -> 4, numOutputBytes -> 1125004, numOutputRows -> 99149]|\n",
      "|0  |2020-08-26 10:13:04|WRITE    |[mode -> Overwrite, partitionBy -> []]|[numFiles -> 4, numOutputBytes -> 1129731, numOutputRows -> 99226]|\n",
      "+---+-------------------+---------+--------------------------------------+------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"####### HISTORY ########\")\n",
    "\n",
    "# Observe history of actions taken on a Delta table\n",
    "# Reference for full history schema: https://docs.delta.io/latest/delta-utility.html\n",
    "history = deltaTable.history().select('version','timestamp','operation', 'operationParameters', \\\n",
    "                                      'operationMetrics') \\\n",
    "                              .withColumnRenamed(\"version\", \"ver\")\n",
    "\n",
    "history.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195KB    2020-08-26 10:13:03  part-00003-e1c13592-efaf-4ca7-9a0f-25484dccc18d-c000.snappy.parquet\n",
      "314KB    2020-08-26 10:13:03  part-00002-25235bcc-3dc3-4a62-b354-10ca68c42a83-c000.snappy.parquet\n",
      "312KB    2020-08-26 10:13:03  part-00001-58b422df-e828-45a4-b95c-ac2f62ee2dc7-c000.snappy.parquet\n",
      "282KB    2020-08-26 10:13:03  part-00000-30f975b9-52a0-4eb4-b72e-1ce6669d9576-c000.snappy.parquet\n",
      "193KB    2020-08-26 10:14:13  part-00003-5e6f6655-260d-4c02-9539-517d20cc04c4-c000.snappy.parquet\n",
      "281KB    2020-08-26 10:14:13  part-00000-0399af6a-0418-4beb-a296-b74b1563bda6-c000.snappy.parquet\n",
      "315KB    2020-08-26 10:14:14  part-00002-454272fb-01fb-4adc-860a-8cb040e4ec52-c000.snappy.parquet\n",
      "310KB    2020-08-26 10:14:14  part-00001-5f7935a6-3fb4-469f-97c0-cfd66dec38a6-c000.snappy.parquet\n",
      "\n",
      "Number of file/s: 8 | Total size: 2.3M\n"
     ]
    }
   ],
   "source": [
    "# Data Files and size on disk\n",
    "\n",
    "files_in_dir(deltaPath, \"parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2KB      2020-08-26 10:13:04  00000000000000000000.json\n",
      "938B     2020-08-26 10:14:14  00000000000000000001.json\n",
      "\n",
      "Number of file/s: 2 | Total size: 8.0K\n"
     ]
    }
   ],
   "source": [
    "# Transaction logs and size on disk\n",
    "\n",
    "files_in_dir(deltaLogPath, \"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(add=None, commitInfo=Row(isBlindAppend=True, operation='WRITE', operationMetrics=Row(numFiles='4', numOutputBytes='1125004', numOutputRows='99149'), operationParameters=Row(mode='Append', partitionBy='[]'), readVersion=0, timestamp=1598451254014)),\n",
       " Row(add=Row(dataChange=True, modificationTime=1598451253000, path='part-00000-0399af6a-0418-4beb-a296-b74b1563bda6-c000.snappy.parquet', size=287535), commitInfo=None),\n",
       " Row(add=Row(dataChange=True, modificationTime=1598451254000, path='part-00001-5f7935a6-3fb4-469f-97c0-cfd66dec38a6-c000.snappy.parquet', size=317603), commitInfo=None),\n",
       " Row(add=Row(dataChange=True, modificationTime=1598451254000, path='part-00002-454272fb-01fb-4adc-860a-8cb040e4ec52-c000.snappy.parquet', size=322207), commitInfo=None),\n",
       " Row(add=Row(dataChange=True, modificationTime=1598451253000, path='part-00003-5e6f6655-260d-4c02-9539-517d20cc04c4-c000.snappy.parquet', size=197659), commitInfo=None)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Peek inside the new transaction log\n",
    "\n",
    "logDF = spark.read.format(\"json\").load(deltaLogPath + \"/00000000000000000001.json\")\n",
    "logDF.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create SQL table to make life easier\n",
    "# Stick with SQL from here on out, where possible.\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    DROP TABLE IF EXISTS SalesDeltaFormat\n",
    "  \"\"\")\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE SalesDeltaFormat\n",
    "    USING DELTA\n",
    "    LOCATION '{}'\n",
    "  \"\"\".format(deltaPath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='salesdeltaformat', database='deltademo', description=None, tableType='EXTERNAL', isTemporary=False),\n",
       " Table(name='salesparquetformat', database='deltademo', description=None, tableType='EXTERNAL', isTemporary=False)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's peek into the catalog and verify that our table was created.\n",
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+----------------------------------------------+-------+\n",
      "|col_name                    |data_type                                     |comment|\n",
      "+----------------------------+----------------------------------------------+-------+\n",
      "|InvoiceNo                   |int                                           |       |\n",
      "|StockCode                   |string                                        |       |\n",
      "|Description                 |string                                        |       |\n",
      "|Quantity                    |int                                           |       |\n",
      "|InvoiceDate                 |string                                        |       |\n",
      "|UnitPrice                   |double                                        |       |\n",
      "|CustomerID                  |int                                           |       |\n",
      "|Country                     |string                                        |       |\n",
      "|                            |                                              |       |\n",
      "|# Partitioning              |                                              |       |\n",
      "|Not partitioned             |                                              |       |\n",
      "|                            |                                              |       |\n",
      "|# Detailed Table Information|                                              |       |\n",
      "|Name                        |deltademo.salesdeltaformat                    |       |\n",
      "|Location                    |file:/home/spark/data/delta/online_retail_data|       |\n",
      "|Provider                    |delta                                         |       |\n",
      "|Table Properties            |[]                                            |       |\n",
      "+----------------------------+----------------------------------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"describe extended SalesDeltaFormat\").show(100, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Invoice # => 563202\n"
     ]
    }
   ],
   "source": [
    "# Let's find a Invoice with only 1 count and use it to test DML.\n",
    "oneRandomInvoice = spark.sql(\"\"\" SELECT InvoiceNo, count(*)\n",
    "                                 FROM SalesDeltaFormat\n",
    "                                 GROUP BY InvoiceNo\n",
    "                                 ORDER BY 2 asc\n",
    "                                 LIMIT 1\n",
    "                             \"\"\").collect()[0][0]\n",
    "\n",
    "print(f\"Random Invoice # => {oneRandomInvoice}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------+---------+---------+---------------------------+--------+---------------+---------+----------+-------+\n",
      "|FileName                                                           |InvoiceNo|StockCode|Description                |Quantity|InvoiceDate    |UnitPrice|CustomerID|Country|\n",
      "+-------------------------------------------------------------------+---------+---------+---------------------------+--------+---------------+---------+----------+-------+\n",
      "|part-00002-454272fb-01fb-4adc-860a-8cb040e4ec52-c000.snappy.parquet|563202   |85066    |CREAM SWEETHEART MINI CHEST|1       |8/14/2011 11:16|12.75    |12722     |France |\n",
      "+-------------------------------------------------------------------+---------+---------+---------------------------+--------+---------------+---------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Before DML (insert)\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "              SELECT SUBSTRING(input_file_name(), -67, 67) AS FileName,\n",
    "                     * FROM SalesDeltaFormat \n",
    "              WHERE InvoiceNo = {oneRandomInvoice}\n",
    "           \"\"\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's add some data to our table\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "               INSERT INTO SalesDeltaFormat\n",
    "               VALUES({oneRandomInvoice}, 2291, \"WORLD'S BEST JAM MAKING SET\", 5, \"08/13/2011 07:58\", 1.45, 15358, \"France\");\n",
    "          \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2KB      2020-08-26 10:13:04  00000000000000000000.json\n",
      "938B     2020-08-26 10:14:14  00000000000000000001.json\n",
      "410B     2020-08-26 10:14:59  00000000000000000002.json\n",
      "\n",
      "Number of file/s: 3 | Total size: 12K\n"
     ]
    }
   ],
   "source": [
    "files_in_dir(deltaLogPath,\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(add=None, commitInfo=Row(isBlindAppend=True, operation='WRITE', operationMetrics=Row(numFiles='1', numOutputBytes='2369', numOutputRows='1'), operationParameters=Row(mode='Append', partitionBy='[]'), readVersion=1, timestamp=1598451299827)),\n",
       " Row(add=Row(dataChange=True, modificationTime=1598451299000, path='part-00000-e061bc4e-947b-4a4b-9cef-1fc47c0598ea-c000.snappy.parquet', size=2369), commitInfo=None)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Schema details: https://docs.delta.io/latest/delta-utility.html\n",
    "\n",
    "logDF = spark.read.format(\"json\").load(deltaLogPath + \"/00000000000000000002.json\")\n",
    "#dfLog.printSchema()\n",
    "logDF.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------+---------+---------+---------------------------+--------+----------------+---------+----------+-------+\n",
      "|FileName                                                           |InvoiceNo|StockCode|Description                |Quantity|InvoiceDate     |UnitPrice|CustomerID|Country|\n",
      "+-------------------------------------------------------------------+---------+---------+---------------------------+--------+----------------+---------+----------+-------+\n",
      "|part-00002-454272fb-01fb-4adc-860a-8cb040e4ec52-c000.snappy.parquet|563202   |85066    |CREAM SWEETHEART MINI CHEST|1       |8/14/2011 11:16 |12.75    |12722     |France |\n",
      "|part-00000-e061bc4e-947b-4a4b-9cef-1fc47c0598ea-c000.snappy.parquet|563202   |2291     |WORLD'S BEST JAM MAKING SET|5       |08/13/2011 07:58|1.45     |15358     |France |\n",
      "+-------------------------------------------------------------------+---------+---------+---------------------------+--------+----------------+---------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# After DML (insert)\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "              SELECT SUBSTRING(input_file_name(), -67, 67) AS FileName, *\n",
    "                     FROM SalesDeltaFormat \n",
    "                     WHERE InvoiceNo = {oneRandomInvoice}\n",
    "           \"\"\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update one invoice\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "              UPDATE SalesDeltaFormat\n",
    "              SET Quantity = Quantity + 1000\n",
    "              WHERE InvoiceNo = {oneRandomInvoice}\n",
    "           \"\"\")\n",
    "\n",
    "#deltaTable.update(\n",
    "#    condition=(\"InvoiceNo = oneRandomInvoice\"),\n",
    "#    set={\"Quantity\": expr(\"Quantity + 1000\")}\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------+---------+---------+---------------------------+--------+----------------+---------+----------+-------+\n",
      "|FileName                                                           |InvoiceNo|StockCode|Description                |Quantity|InvoiceDate     |UnitPrice|CustomerID|Country|\n",
      "+-------------------------------------------------------------------+---------+---------+---------------------------+--------+----------------+---------+----------+-------+\n",
      "|part-00000-ba14adf0-b9e9-4ce8-9eff-d39bf1ad4d55-c000.snappy.parquet|563202   |85066    |CREAM SWEETHEART MINI CHEST|1001    |8/14/2011 11:16 |12.75    |12722     |France |\n",
      "|part-00001-0eba87ae-1189-4cbd-b3ea-3ece7812113e-c000.snappy.parquet|563202   |2291     |WORLD'S BEST JAM MAKING SET|1005    |08/13/2011 07:58|1.45     |15358     |France |\n",
      "+-------------------------------------------------------------------+---------+---------+---------------------------+--------+----------------+---------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# After Update\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "              SELECT \n",
    "              SUBSTRING(input_file_name(), -67, 67) AS FileName, *\n",
    "              FROM SalesDeltaFormat \n",
    "              WHERE InvoiceNo = {oneRandomInvoice}\n",
    "           \"\"\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### HISTORY ########\n",
      "+---+---------+----------------------------------------+---------------------------------------------------------------------------------------+\n",
      "|ver|operation|operationParameters                     |operationMetrics                                                                       |\n",
      "+---+---------+----------------------------------------+---------------------------------------------------------------------------------------+\n",
      "|3  |UPDATE   |[predicate -> (InvoiceNo#2642 = 563202)]|[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 2, numCopiedRows -> 29509]|\n",
      "|2  |WRITE    |[mode -> Append, partitionBy -> []]     |[numFiles -> 1, numOutputBytes -> 2369, numOutputRows -> 1]                            |\n",
      "|1  |WRITE    |[mode -> Append, partitionBy -> []]     |[numFiles -> 4, numOutputBytes -> 1125004, numOutputRows -> 99149]                     |\n",
      "|0  |WRITE    |[mode -> Overwrite, partitionBy -> []]  |[numFiles -> 4, numOutputBytes -> 1129731, numOutputRows -> 99226]                     |\n",
      "+---+---------+----------------------------------------+---------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"####### HISTORY ########\")\n",
    "\n",
    "# Show which datafile was removed.\n",
    "\n",
    "# Observe history of actions taken on a Delta table\n",
    "# spark.sql not supported in 0.7.0 OSS Delta\n",
    "history = deltaTable.history().select('version','operation', 'operationParameters', \\\n",
    "                                      'operationMetrics') \\\n",
    "                              .withColumnRenamed(\"version\", \"ver\")\n",
    "\n",
    "history.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195KB    2020-08-26 10:13:03  part-00003-e1c13592-efaf-4ca7-9a0f-25484dccc18d-c000.snappy.parquet\n",
      "314KB    2020-08-26 10:13:03  part-00002-25235bcc-3dc3-4a62-b354-10ca68c42a83-c000.snappy.parquet\n",
      "312KB    2020-08-26 10:13:03  part-00001-58b422df-e828-45a4-b95c-ac2f62ee2dc7-c000.snappy.parquet\n",
      "282KB    2020-08-26 10:13:03  part-00000-30f975b9-52a0-4eb4-b72e-1ce6669d9576-c000.snappy.parquet\n",
      "193KB    2020-08-26 10:14:13  part-00003-5e6f6655-260d-4c02-9539-517d20cc04c4-c000.snappy.parquet\n",
      "281KB    2020-08-26 10:14:13  part-00000-0399af6a-0418-4beb-a296-b74b1563bda6-c000.snappy.parquet\n",
      "315KB    2020-08-26 10:14:14  part-00002-454272fb-01fb-4adc-860a-8cb040e4ec52-c000.snappy.parquet\n",
      "310KB    2020-08-26 10:14:14  part-00001-5f7935a6-3fb4-469f-97c0-cfd66dec38a6-c000.snappy.parquet\n",
      "2KB      2020-08-26 10:14:59  part-00000-e061bc4e-947b-4a4b-9cef-1fc47c0598ea-c000.snappy.parquet\n",
      "2KB      2020-08-26 10:15:18  part-00001-0eba87ae-1189-4cbd-b3ea-3ece7812113e-c000.snappy.parquet\n",
      "315KB    2020-08-26 10:15:18  part-00000-ba14adf0-b9e9-4ce8-9eff-d39bf1ad4d55-c000.snappy.parquet\n",
      "\n",
      "Number of file/s: 11 | Total size: 2.6M\n"
     ]
    }
   ],
   "source": [
    "files_in_dir(deltaPath, \"parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2KB      2020-08-26 10:13:04  00000000000000000000.json\n",
      "938B     2020-08-26 10:14:14  00000000000000000001.json\n",
      "410B     2020-08-26 10:14:59  00000000000000000002.json\n",
      "902B     2020-08-26 10:15:18  00000000000000000003.json\n",
      "\n",
      "Number of file/s: 4 | Total size: 16K\n"
     ]
    }
   ],
   "source": [
    "files_in_dir(deltaLogPath,\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(add=None, commitInfo=Row(isBlindAppend=False, operation='UPDATE', operationMetrics=Row(numAddedFiles='2', numCopiedRows='29509', numRemovedFiles='2', numUpdatedRows='2'), operationParameters=Row(predicate='(InvoiceNo#2642 = 563202)'), readVersion=2, timestamp=1598451318801), remove=None),\n",
       " Row(add=None, commitInfo=None, remove=Row(dataChange=True, deletionTimestamp=1598451318624, path='part-00000-e061bc4e-947b-4a4b-9cef-1fc47c0598ea-c000.snappy.parquet')),\n",
       " Row(add=None, commitInfo=None, remove=Row(dataChange=True, deletionTimestamp=1598451318624, path='part-00002-454272fb-01fb-4adc-860a-8cb040e4ec52-c000.snappy.parquet')),\n",
       " Row(add=Row(dataChange=True, modificationTime=1598451318000, path='part-00000-ba14adf0-b9e9-4ce8-9eff-d39bf1ad4d55-c000.snappy.parquet', size=322239), commitInfo=None, remove=None),\n",
       " Row(add=Row(dataChange=True, modificationTime=1598451318000, path='part-00001-0eba87ae-1189-4cbd-b3ea-3ece7812113e-c000.snappy.parquet', size=2369), commitInfo=None, remove=None)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Schema details: https://docs.delta.io/latest/delta-utility.html\n",
    "\n",
    "logDF = spark.read.format(\"json\").load(deltaLogPath + \"/00000000000000000003.json\")\n",
    "#dfLog.printSchema()\n",
    "logDF.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------+---------+---------+---------------------------+--------+----------------+---------+----------+-------+\n",
      "|FileName                                                           |InvoiceNo|StockCode|Description                |Quantity|InvoiceDate     |UnitPrice|CustomerID|Country|\n",
      "+-------------------------------------------------------------------+---------+---------+---------------------------+--------+----------------+---------+----------+-------+\n",
      "|part-00000-ba14adf0-b9e9-4ce8-9eff-d39bf1ad4d55-c000.snappy.parquet|563202   |85066    |CREAM SWEETHEART MINI CHEST|1001    |8/14/2011 11:16 |12.75    |12722     |France |\n",
      "|part-00001-0eba87ae-1189-4cbd-b3ea-3ece7812113e-c000.snappy.parquet|563202   |2291     |WORLD'S BEST JAM MAKING SET|1005    |08/13/2011 07:58|1.45     |15358     |France |\n",
      "+-------------------------------------------------------------------+---------+---------+---------------------------+--------+----------------+---------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Before DML (delete)\n",
    "\n",
    "spark.sql(f\"\"\"select \n",
    "          substring(input_file_name(), -67, 67) as FileName,\n",
    "          * from SalesDeltaFormat \n",
    "          where InvoiceNo = {oneRandomInvoice}\"\"\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://github.com/delta-io/delta/blob/master/examples/python/quickstart.py\n",
    "# Delete and invoice (two records)\n",
    "\n",
    "# This results in one new file being created.  One file had just the one record so it does not have to be re-created\n",
    "# Each of the two records were in two different files. One of those files had only one record so it did not have to be re-created.\n",
    "\n",
    "spark.sql(f\"DELETE FROM SalesDeltaFormat WHERE InvoiceNo = {oneRandomInvoice}\")\n",
    "\n",
    "# deltaTable.delete(\n",
    "#    condition=(\"InvoiceNo = {537617}\")\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "|FileName|InvoiceNo|StockCode|Description|Quantity|InvoiceDate|UnitPrice|CustomerID|Country|\n",
      "+--------+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "+--------+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# After DML (delete)\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "              SELECT \n",
    "              SUBSTRING(input_file_name(), -67, 67) as FileName, *\n",
    "              FROM SalesDeltaFormat \n",
    "              WHERE InvoiceNo = {oneRandomInvoice}\n",
    "          \"\"\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### HISTORY ########\n",
      "+---+---------+----------------------------------------------------------------------------------+---------------------------------------------------------------------------------------+\n",
      "|ver|operation|operationParameters                                                               |operationMetrics                                                                       |\n",
      "+---+---------+----------------------------------------------------------------------------------+---------------------------------------------------------------------------------------+\n",
      "|4  |DELETE   |[predicate -> [\"(spark_catalog.deltademo.SalesDeltaFormat.`InvoiceNo` = 563202)\"]]|[numRemovedFiles -> 2, numDeletedRows -> 2, numAddedFiles -> 1, numCopiedRows -> 29509]|\n",
      "|3  |UPDATE   |[predicate -> (InvoiceNo#2642 = 563202)]                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 2, numCopiedRows -> 29509]|\n",
      "|2  |WRITE    |[mode -> Append, partitionBy -> []]                                               |[numFiles -> 1, numOutputBytes -> 2369, numOutputRows -> 1]                            |\n",
      "|1  |WRITE    |[mode -> Append, partitionBy -> []]                                               |[numFiles -> 4, numOutputBytes -> 1125004, numOutputRows -> 99149]                     |\n",
      "|0  |WRITE    |[mode -> Overwrite, partitionBy -> []]                                            |[numFiles -> 4, numOutputBytes -> 1129731, numOutputRows -> 99226]                     |\n",
      "+---+---------+----------------------------------------------------------------------------------+---------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"####### HISTORY ########\")\n",
    "\n",
    "# Observe history of actions taken on a Delta table\n",
    "history = deltaTable.history().select('version','operation', 'operationParameters', \\\n",
    "                                      'operationMetrics') \\\n",
    "                              .withColumnRenamed(\"version\", \"ver\")\n",
    "\n",
    "history.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195KB    2020-08-26 10:13:03  part-00003-e1c13592-efaf-4ca7-9a0f-25484dccc18d-c000.snappy.parquet\n",
      "314KB    2020-08-26 10:13:03  part-00002-25235bcc-3dc3-4a62-b354-10ca68c42a83-c000.snappy.parquet\n",
      "312KB    2020-08-26 10:13:03  part-00001-58b422df-e828-45a4-b95c-ac2f62ee2dc7-c000.snappy.parquet\n",
      "282KB    2020-08-26 10:13:03  part-00000-30f975b9-52a0-4eb4-b72e-1ce6669d9576-c000.snappy.parquet\n",
      "193KB    2020-08-26 10:14:13  part-00003-5e6f6655-260d-4c02-9539-517d20cc04c4-c000.snappy.parquet\n",
      "281KB    2020-08-26 10:14:13  part-00000-0399af6a-0418-4beb-a296-b74b1563bda6-c000.snappy.parquet\n",
      "315KB    2020-08-26 10:14:14  part-00002-454272fb-01fb-4adc-860a-8cb040e4ec52-c000.snappy.parquet\n",
      "310KB    2020-08-26 10:14:14  part-00001-5f7935a6-3fb4-469f-97c0-cfd66dec38a6-c000.snappy.parquet\n",
      "2KB      2020-08-26 10:14:59  part-00000-e061bc4e-947b-4a4b-9cef-1fc47c0598ea-c000.snappy.parquet\n",
      "2KB      2020-08-26 10:15:18  part-00001-0eba87ae-1189-4cbd-b3ea-3ece7812113e-c000.snappy.parquet\n",
      "315KB    2020-08-26 10:15:18  part-00000-ba14adf0-b9e9-4ce8-9eff-d39bf1ad4d55-c000.snappy.parquet\n",
      "315KB    2020-08-26 10:16:31  part-00000-54540c53-d90d-4661-bc10-f81f739e556f-c000.snappy.parquet\n",
      "\n",
      "Number of file/s: 12 | Total size: 2.9M\n"
     ]
    }
   ],
   "source": [
    "files_in_dir(deltaPath, \"parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2KB      2020-08-26 10:13:04  00000000000000000000.json\n",
      "938B     2020-08-26 10:14:14  00000000000000000001.json\n",
      "410B     2020-08-26 10:14:59  00000000000000000002.json\n",
      "902B     2020-08-26 10:15:18  00000000000000000003.json\n",
      "775B     2020-08-26 10:16:31  00000000000000000004.json\n",
      "\n",
      "Number of file/s: 5 | Total size: 20K\n"
     ]
    }
   ],
   "source": [
    "files_in_dir(deltaLogPath,\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(add=None, commitInfo=Row(isBlindAppend=False, operation='DELETE', operationMetrics=Row(numAddedFiles='1', numCopiedRows='29509', numDeletedRows='2', numRemovedFiles='2'), operationParameters=Row(predicate='[\"(spark_catalog.deltademo.SalesDeltaFormat.`InvoiceNo` = 563202)\"]'), readVersion=3, timestamp=1598451391965), remove=None),\n",
       " Row(add=None, commitInfo=None, remove=Row(dataChange=True, deletionTimestamp=1598451391963, path='part-00001-0eba87ae-1189-4cbd-b3ea-3ece7812113e-c000.snappy.parquet')),\n",
       " Row(add=None, commitInfo=None, remove=Row(dataChange=True, deletionTimestamp=1598451391963, path='part-00000-ba14adf0-b9e9-4ce8-9eff-d39bf1ad4d55-c000.snappy.parquet')),\n",
       " Row(add=Row(dataChange=True, modificationTime=1598451391000, path='part-00000-54540c53-d90d-4661-bc10-f81f739e556f-c000.snappy.parquet', size=322988), commitInfo=None, remove=None)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logDF = spark.read.format(\"json\").load(deltaLogPath + \"/00000000000000000004.json\")\n",
    "#dfLog.printSchema()\n",
    "logDF.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomy update 5 random invoices to force a checkpoint\n",
    "\n",
    "count = 0\n",
    "anInvoice = retailSalesData2.select(\"InvoiceNo\").orderBy(rand()).limit(1).collect()[0][0]\n",
    "\n",
    "while (count <= 5):\n",
    "  deltaTable.update(\n",
    "    condition=(f\"InvoiceNo = {anInvoice}\"),\n",
    "    set={\"Quantity\": expr(\"Quantity + 100\")})\n",
    "\n",
    "  count = count + 1\n",
    "  anInvoice = retailSalesData2.select(\"InvoiceNo\").orderBy(rand()).limit(1).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2KB      2020-08-26 10:13:04  00000000000000000000.json\n",
      "938B     2020-08-26 10:14:14  00000000000000000001.json\n",
      "410B     2020-08-26 10:14:59  00000000000000000002.json\n",
      "902B     2020-08-26 10:15:18  00000000000000000003.json\n",
      "775B     2020-08-26 10:16:31  00000000000000000004.json\n",
      "905B     2020-08-26 10:17:59  00000000000000000005.json\n",
      "904B     2020-08-26 10:18:00  00000000000000000006.json\n",
      "905B     2020-08-26 10:18:02  00000000000000000007.json\n",
      "905B     2020-08-26 10:18:04  00000000000000000008.json\n",
      "905B     2020-08-26 10:18:05  00000000000000000009.json\n",
      "905B     2020-08-26 10:18:07  00000000000000000010.json\n",
      "17KB     2020-08-26 10:18:08  00000000000000000010.checkpoint.parquet\n",
      "\n",
      "Number of file/s: 12 | Total size: 76K\n"
     ]
    }
   ],
   "source": [
    "files_in_dir(deltaLogPath,\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+----------+\n",
      "|txn |add                                                                                                      |remove                                                                                     |metaData                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |protocol|commitInfo|\n",
      "+----+---------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+----------+\n",
      "|null|[part-00001-93d4d843-87fb-456c-89c5-3c7db9f9e99d-c000.snappy.parquet, [], 287532, 1598451485000, false,,]|null                                                                                       |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|[part-00001-9b04da93-ebc7-46ef-88db-987405272860-c000.snappy.parquet, [], 317644, 1598451487000, false,,]|null                                                                                       |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|[part-00000-920f6196-8a7e-421f-a9e8-8a59960ed98d-c000.snappy.parquet, [], 288508, 1598451485000, false,,]|null                                                                                       |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|null                                                                                                     |[part-00001-58b422df-e828-45a4-b95c-ac2f62ee2dc7-c000.snappy.parquet, 1598451480626, false]|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|null                                                                                                     |[part-00000-b2e3b73f-e67e-4eef-9584-d30cba8ada87-c000.snappy.parquet, 1598451482310, false]|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|null                                                                                                     |[part-00001-642392d4-2c5e-4f6a-902d-9a7c5af90190-c000.snappy.parquet, 1598451482310, false]|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|[part-00003-5e6f6655-260d-4c02-9539-517d20cc04c4-c000.snappy.parquet, [], 197659, 1598451253000, false,,]|null                                                                                       |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|null                                                                                                     |[part-00000-54540c53-d90d-4661-bc10-f81f739e556f-c000.snappy.parquet, 1598451478873, false]|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|[part-00003-e1c13592-efaf-4ca7-9a0f-25484dccc18d-c000.snappy.parquet, [], 199800, 1598451183000, false,,]|null                                                                                       |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|null                                                                                                     |[part-00000-e061bc4e-947b-4a4b-9cef-1fc47c0598ea-c000.snappy.parquet, 1598451318624, false]|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|null                                                                                                     |[part-00001-6bbaab90-8346-44c2-9b63-154772010091-c000.snappy.parquet, 1598451487230, false]|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|null                                                                                                     |[part-00002-454272fb-01fb-4adc-860a-8cb040e4ec52-c000.snappy.parquet, 1598451318624, false]|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|[part-00000-435ac137-7b40-43b6-98ea-f57e47b1b898-c000.snappy.parquet, [], 319790, 1598451487000, false,,]|null                                                                                       |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|null                                                                                                     |[part-00000-ba14adf0-b9e9-4ce8-9eff-d39bf1ad4d55-c000.snappy.parquet, 1598451391963, false]|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|null                                                                                                     |[part-00001-0eba87ae-1189-4cbd-b3ea-3ece7812113e-c000.snappy.parquet, 1598451391963, false]|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|null                                                                                                     |[part-00000-30f975b9-52a0-4eb4-b72e-1ce6669d9576-c000.snappy.parquet, 1598451483991, false]|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|null                                                                                                     |[part-00001-5f7935a6-3fb4-469f-97c0-cfd66dec38a6-c000.snappy.parquet, 1598451480626, false]|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|[part-00001-7e1684e4-3842-499f-b548-5e3feb18ab3a-c000.snappy.parquet, [], 321724, 1598451479000, false,,]|null                                                                                       |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|[part-00000-4c305d94-5f07-4ed5-b0fc-43216acbdba7-c000.snappy.parquet, [], 323000, 1598451479000, false,,]|null                                                                                       |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|null                                                                                                     |null                                                                                       |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |[1, 2]  |null      |\n",
      "|null|null                                                                                                     |null                                                                                       |[4126e7fa-86b6-4189-b565-79b85f699224,,, [parquet, []], {\"type\":\"struct\",\"fields\":[{\"name\":\"InvoiceNo\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"StockCode\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"Description\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"Quantity\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"InvoiceDate\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"UnitPrice\",\"type\":\"double\",\"nullable\":true,\"metadata\":{}},{\"name\":\"CustomerID\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"Country\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}, [], [], 1598451182505]|null    |null      |\n",
      "|null|null                                                                                                     |[part-00000-0399af6a-0418-4beb-a296-b74b1563bda6-c000.snappy.parquet, 1598451483991, false]|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|null                                                                                                     |[part-00000-a79e958c-d460-484b-ba1a-8cba5893c15d-c000.snappy.parquet, 1598451487230, false]|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|null                                                                                                     |[part-00001-150dba95-8b21-4e5e-bce5-6725dcce2f28-c000.snappy.parquet, 1598451485496, false]|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|null                                                                                                     |[part-00000-8f237632-d51e-46c1-858c-4c873ed1e2ba-c000.snappy.parquet, 1598451485496, false]|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "|null|null                                                                                                     |[part-00002-25235bcc-3dc3-4a62-b354-10ca68c42a83-c000.snappy.parquet, 1598451478873, false]|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null    |null      |\n",
      "+----+---------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "checkPointDF = spark.read.format(\"parquet\").load(deltaLogPath + \"/00000000000000000010.checkpoint.parquet\")\n",
    "checkPointDF.show(100, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkPointFile10 =(\n",
    "    checkPointDF.select(col(\"add.path\").alias(\"FileAdded\"),\n",
    "                        col(\"add.modificationTime\").alias(\"DateAdded\"),\n",
    "                        col(\"remove.path\").alias(\"FileDeleted\"),\n",
    "                        col(\"remove.deletionTimestamp\").alias(\"DateDeleted\"))\n",
    "                .orderBy([\"DateAdded\",\"DateDeleted\"], ascending=[True,False])\n",
    ")\n",
    "\n",
    "spark.sql(\"DROP TABLE IF EXISTS tbl_checkpointfile\")\n",
    "spark.sql(\"CREATE TABLE IF NOT EXISTS tbl_checkpointfile (Action string, filename string, ActionDate Long)\")\n",
    "\n",
    "checkPointFile10.createOrReplaceTempView(\"vw_checkpointfile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------+-------------+-------------------------------------------------------------------+-------------+\n",
      "|FileAdded                                                          |DateAdded    |FileDeleted                                                        |DateDeleted  |\n",
      "+-------------------------------------------------------------------+-------------+-------------------------------------------------------------------+-------------+\n",
      "|null                                                               |null         |part-00001-6bbaab90-8346-44c2-9b63-154772010091-c000.snappy.parquet|1598451487230|\n",
      "|null                                                               |null         |part-00000-a79e958c-d460-484b-ba1a-8cba5893c15d-c000.snappy.parquet|1598451487230|\n",
      "|null                                                               |null         |part-00001-150dba95-8b21-4e5e-bce5-6725dcce2f28-c000.snappy.parquet|1598451485496|\n",
      "|null                                                               |null         |part-00000-8f237632-d51e-46c1-858c-4c873ed1e2ba-c000.snappy.parquet|1598451485496|\n",
      "|null                                                               |null         |part-00000-30f975b9-52a0-4eb4-b72e-1ce6669d9576-c000.snappy.parquet|1598451483991|\n",
      "|null                                                               |null         |part-00000-0399af6a-0418-4beb-a296-b74b1563bda6-c000.snappy.parquet|1598451483991|\n",
      "|null                                                               |null         |part-00000-b2e3b73f-e67e-4eef-9584-d30cba8ada87-c000.snappy.parquet|1598451482310|\n",
      "|null                                                               |null         |part-00001-642392d4-2c5e-4f6a-902d-9a7c5af90190-c000.snappy.parquet|1598451482310|\n",
      "|null                                                               |null         |part-00001-58b422df-e828-45a4-b95c-ac2f62ee2dc7-c000.snappy.parquet|1598451480626|\n",
      "|null                                                               |null         |part-00001-5f7935a6-3fb4-469f-97c0-cfd66dec38a6-c000.snappy.parquet|1598451480626|\n",
      "|null                                                               |null         |part-00000-54540c53-d90d-4661-bc10-f81f739e556f-c000.snappy.parquet|1598451478873|\n",
      "|null                                                               |null         |part-00002-25235bcc-3dc3-4a62-b354-10ca68c42a83-c000.snappy.parquet|1598451478873|\n",
      "|null                                                               |null         |part-00000-ba14adf0-b9e9-4ce8-9eff-d39bf1ad4d55-c000.snappy.parquet|1598451391963|\n",
      "|null                                                               |null         |part-00001-0eba87ae-1189-4cbd-b3ea-3ece7812113e-c000.snappy.parquet|1598451391963|\n",
      "|null                                                               |null         |part-00000-e061bc4e-947b-4a4b-9cef-1fc47c0598ea-c000.snappy.parquet|1598451318624|\n",
      "|null                                                               |null         |part-00002-454272fb-01fb-4adc-860a-8cb040e4ec52-c000.snappy.parquet|1598451318624|\n",
      "|null                                                               |null         |null                                                               |null         |\n",
      "|null                                                               |null         |null                                                               |null         |\n",
      "|part-00003-e1c13592-efaf-4ca7-9a0f-25484dccc18d-c000.snappy.parquet|1598451183000|null                                                               |null         |\n",
      "|part-00003-5e6f6655-260d-4c02-9539-517d20cc04c4-c000.snappy.parquet|1598451253000|null                                                               |null         |\n",
      "|part-00001-7e1684e4-3842-499f-b548-5e3feb18ab3a-c000.snappy.parquet|1598451479000|null                                                               |null         |\n",
      "|part-00000-4c305d94-5f07-4ed5-b0fc-43216acbdba7-c000.snappy.parquet|1598451479000|null                                                               |null         |\n",
      "|part-00001-93d4d843-87fb-456c-89c5-3c7db9f9e99d-c000.snappy.parquet|1598451485000|null                                                               |null         |\n",
      "|part-00000-920f6196-8a7e-421f-a9e8-8a59960ed98d-c000.snappy.parquet|1598451485000|null                                                               |null         |\n",
      "|part-00001-9b04da93-ebc7-46ef-88db-987405272860-c000.snappy.parquet|1598451487000|null                                                               |null         |\n",
      "|part-00000-435ac137-7b40-43b6-98ea-f57e47b1b898-c000.snappy.parquet|1598451487000|null                                                               |null         |\n",
      "+-------------------------------------------------------------------+-------------+-------------------------------------------------------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from vw_checkpointfile limit 100\").show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "          INSERT INTO tbl_checkpointfile\n",
    "          SELECT \"Add\", FileAdded, DateAdded\n",
    "          FROM vw_checkpointfile\n",
    "          WHERE FileAdded IS NOT NULL\n",
    "          \"\"\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "          INSERT INTO tbl_checkpointfile\n",
    "          SELECT \"Delete\", FileDeleted, DateDeleted\n",
    "          FROM vw_checkpointfile\n",
    "          WHERE FileDeleted IS NOT NULL\n",
    "          \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------------------------------------------------------+-------------------+\n",
      "|Action|File Name                                                          |ActionDate         |\n",
      "+------+-------------------------------------------------------------------+-------------------+\n",
      "|Add   |part-00003-e1c13592-efaf-4ca7-9a0f-25484dccc18d-c000.snappy.parquet|2020-08-26 10:13:03|\n",
      "|Add   |part-00003-5e6f6655-260d-4c02-9539-517d20cc04c4-c000.snappy.parquet|2020-08-26 10:14:13|\n",
      "|Delete|part-00000-e061bc4e-947b-4a4b-9cef-1fc47c0598ea-c000.snappy.parquet|2020-08-26 10:15:18|\n",
      "|Delete|part-00002-454272fb-01fb-4adc-860a-8cb040e4ec52-c000.snappy.parquet|2020-08-26 10:15:18|\n",
      "|Delete|part-00000-ba14adf0-b9e9-4ce8-9eff-d39bf1ad4d55-c000.snappy.parquet|2020-08-26 10:16:31|\n",
      "|Delete|part-00001-0eba87ae-1189-4cbd-b3ea-3ece7812113e-c000.snappy.parquet|2020-08-26 10:16:31|\n",
      "|Delete|part-00002-25235bcc-3dc3-4a62-b354-10ca68c42a83-c000.snappy.parquet|2020-08-26 10:17:58|\n",
      "|Delete|part-00000-54540c53-d90d-4661-bc10-f81f739e556f-c000.snappy.parquet|2020-08-26 10:17:58|\n",
      "|Add   |part-00001-7e1684e4-3842-499f-b548-5e3feb18ab3a-c000.snappy.parquet|2020-08-26 10:17:59|\n",
      "|Add   |part-00000-4c305d94-5f07-4ed5-b0fc-43216acbdba7-c000.snappy.parquet|2020-08-26 10:17:59|\n",
      "|Delete|part-00001-58b422df-e828-45a4-b95c-ac2f62ee2dc7-c000.snappy.parquet|2020-08-26 10:18:00|\n",
      "|Delete|part-00001-5f7935a6-3fb4-469f-97c0-cfd66dec38a6-c000.snappy.parquet|2020-08-26 10:18:00|\n",
      "|Delete|part-00001-642392d4-2c5e-4f6a-902d-9a7c5af90190-c000.snappy.parquet|2020-08-26 10:18:02|\n",
      "|Delete|part-00000-b2e3b73f-e67e-4eef-9584-d30cba8ada87-c000.snappy.parquet|2020-08-26 10:18:02|\n",
      "|Delete|part-00000-30f975b9-52a0-4eb4-b72e-1ce6669d9576-c000.snappy.parquet|2020-08-26 10:18:03|\n",
      "|Delete|part-00000-0399af6a-0418-4beb-a296-b74b1563bda6-c000.snappy.parquet|2020-08-26 10:18:03|\n",
      "|Add   |part-00000-920f6196-8a7e-421f-a9e8-8a59960ed98d-c000.snappy.parquet|2020-08-26 10:18:05|\n",
      "|Delete|part-00000-8f237632-d51e-46c1-858c-4c873ed1e2ba-c000.snappy.parquet|2020-08-26 10:18:05|\n",
      "|Add   |part-00001-93d4d843-87fb-456c-89c5-3c7db9f9e99d-c000.snappy.parquet|2020-08-26 10:18:05|\n",
      "|Delete|part-00001-150dba95-8b21-4e5e-bce5-6725dcce2f28-c000.snappy.parquet|2020-08-26 10:18:05|\n",
      "|Add   |part-00001-9b04da93-ebc7-46ef-88db-987405272860-c000.snappy.parquet|2020-08-26 10:18:07|\n",
      "|Delete|part-00001-6bbaab90-8346-44c2-9b63-154772010091-c000.snappy.parquet|2020-08-26 10:18:07|\n",
      "|Add   |part-00000-435ac137-7b40-43b6-98ea-f57e47b1b898-c000.snappy.parquet|2020-08-26 10:18:07|\n",
      "|Delete|part-00000-a79e958c-d460-484b-ba1a-8cba5893c15d-c000.snappy.parquet|2020-08-26 10:18:07|\n",
      "+------+-------------------------------------------------------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "           SELECT Action, \n",
    "                  filename as `File Name`, \n",
    "                  from_unixtime(actiondate/1e3) AS `ActionDate`\n",
    "           FROM tbl_checkpointfile \n",
    "           order by ActionDate asc\n",
    "          \"\"\").show(200, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's add some data to our table by doing a merge\n",
    "# Do this to show how json logs pick up after checkpoint\n",
    "\n",
    "# Create a tiny dataframe to use with merge\n",
    "mergeSalesData= cleanSalesDataDF.sample(withReplacement=False, fraction=.0001, seed=13)\n",
    "mergeSalesData.createOrReplaceTempView(\"vw_mergeSalesData\")\n",
    "\n",
    "# User-defined commit metadata\n",
    "spark.sql(f\"\"\"\n",
    "               SET spark.databricks.delta.commitInfo.userMetadata=08-25-2020 Data Merge;\n",
    "          \"\"\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "          MERGE INTO SalesDeltaFormat\n",
    "          USING vw_mergeSalesData\n",
    "          ON SalesDeltaFormat.StockCode = vw_mergeSalesData.StockCode\n",
    "           AND SalesDeltaFormat.InvoiceNo = vw_mergeSalesData.InvoiceNo\n",
    "          WHEN MATCHED THEN\n",
    "            UPDATE SET *\n",
    "          WHEN NOT MATCHED\n",
    "            THEN INSERT *\n",
    "          \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### HISTORY ########\n",
      "+---+---------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|ver|operation|operationParameters                                                                                                                                                                               |operationMetrics                                                                                                                                                                                                       |\n",
      "+---+---------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|11 |MERGE    |[predicate -> ((spark_catalog.deltademo.SalesDeltaFormat.`StockCode` = vw_mergesalesdata.`StockCode`) AND (spark_catalog.deltademo.SalesDeltaFormat.`InvoiceNo` = vw_mergesalesdata.`InvoiceNo`))]|[numTargetRowsCopied -> 198349, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 4, numTargetRowsInserted -> 26, numTargetRowsUpdated -> 25, numOutputRows -> 198400, numSourceRows -> 46, numTargetFilesRemoved -> 8]|\n",
      "|10 |UPDATE   |[predicate -> (InvoiceNo#1116 = 560368)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 54, numCopiedRows -> 54339]                                                                                                                               |\n",
      "|9  |UPDATE   |[predicate -> (InvoiceNo#1116 = 537375)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 28, numCopiedRows -> 50093]                                                                                                                               |\n",
      "|8  |UPDATE   |[predicate -> (InvoiceNo#1116 = 546421)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 21, numCopiedRows -> 50100]                                                                                                                               |\n",
      "|7  |UPDATE   |[predicate -> (InvoiceNo#1116 = 560079)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 15, numCopiedRows -> 54378]                                                                                                                               |\n",
      "|6  |UPDATE   |[predicate -> (InvoiceNo#1116 = 560363)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 6, numCopiedRows -> 54387]                                                                                                                                |\n",
      "|5  |UPDATE   |[predicate -> (InvoiceNo#1116 = 573126)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 11, numCopiedRows -> 58914]                                                                                                                               |\n",
      "|4  |DELETE   |[predicate -> [\"(spark_catalog.deltademo.SalesDeltaFormat.`InvoiceNo` = 563202)\"]]                                                                                                                |[numRemovedFiles -> 2, numDeletedRows -> 2, numAddedFiles -> 1, numCopiedRows -> 29509]                                                                                                                                |\n",
      "|3  |UPDATE   |[predicate -> (InvoiceNo#2642 = 563202)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 2, numCopiedRows -> 29509]                                                                                                                                |\n",
      "|2  |WRITE    |[mode -> Append, partitionBy -> []]                                                                                                                                                               |[numFiles -> 1, numOutputBytes -> 2369, numOutputRows -> 1]                                                                                                                                                            |\n",
      "|1  |WRITE    |[mode -> Append, partitionBy -> []]                                                                                                                                                               |[numFiles -> 4, numOutputBytes -> 1125004, numOutputRows -> 99149]                                                                                                                                                     |\n",
      "|0  |WRITE    |[mode -> Overwrite, partitionBy -> []]                                                                                                                                                            |[numFiles -> 4, numOutputBytes -> 1129731, numOutputRows -> 99226]                                                                                                                                                     |\n",
      "+---+---------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"####### HISTORY ########\")\n",
    "\n",
    "# Observe history of actions taken on a Delta table\n",
    "history = deltaTable.history().select('version','operation', 'operationParameters', \\\n",
    "                                      'operationMetrics') \\\n",
    "                              .withColumnRenamed(\"version\", \"ver\")\n",
    "\n",
    "history.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2KB      2020-08-26 10:13:04  00000000000000000000.json\n",
      "938B     2020-08-26 10:14:14  00000000000000000001.json\n",
      "410B     2020-08-26 10:14:59  00000000000000000002.json\n",
      "902B     2020-08-26 10:15:18  00000000000000000003.json\n",
      "775B     2020-08-26 10:16:31  00000000000000000004.json\n",
      "905B     2020-08-26 10:17:59  00000000000000000005.json\n",
      "904B     2020-08-26 10:18:00  00000000000000000006.json\n",
      "905B     2020-08-26 10:18:02  00000000000000000007.json\n",
      "905B     2020-08-26 10:18:04  00000000000000000008.json\n",
      "905B     2020-08-26 10:18:05  00000000000000000009.json\n",
      "905B     2020-08-26 10:18:07  00000000000000000010.json\n",
      "17KB     2020-08-26 10:18:08  00000000000000000010.checkpoint.parquet\n",
      "2KB      2020-08-26 10:19:36  00000000000000000011.json\n",
      "\n",
      "Number of file/s: 13 | Total size: 80K\n"
     ]
    }
   ],
   "source": [
    "files_in_dir(deltaLogPath,\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(add=None, commitInfo=Row(isBlindAppend=False, operation='MERGE', operationMetrics=Row(numOutputRows='198400', numSourceRows='46', numTargetFilesAdded='4', numTargetFilesRemoved='8', numTargetRowsCopied='198349', numTargetRowsDeleted='0', numTargetRowsInserted='26', numTargetRowsUpdated='25'), operationParameters=Row(predicate='((spark_catalog.deltademo.SalesDeltaFormat.`StockCode` = vw_mergesalesdata.`StockCode`) AND (spark_catalog.deltademo.SalesDeltaFormat.`InvoiceNo` = vw_mergesalesdata.`InvoiceNo`))'), readVersion=10, timestamp=1598451576336, userMetadata='08-25-2020 Data Merge;'), remove=None),\n",
       " Row(add=None, commitInfo=None, remove=Row(dataChange=True, deletionTimestamp=1598451576332, path='part-00001-93d4d843-87fb-456c-89c5-3c7db9f9e99d-c000.snappy.parquet')),\n",
       " Row(add=None, commitInfo=None, remove=Row(dataChange=True, deletionTimestamp=1598451576335, path='part-00000-4c305d94-5f07-4ed5-b0fc-43216acbdba7-c000.snappy.parquet')),\n",
       " Row(add=None, commitInfo=None, remove=Row(dataChange=True, deletionTimestamp=1598451576335, path='part-00001-7e1684e4-3842-499f-b548-5e3feb18ab3a-c000.snappy.parquet')),\n",
       " Row(add=None, commitInfo=None, remove=Row(dataChange=True, deletionTimestamp=1598451576335, path='part-00000-920f6196-8a7e-421f-a9e8-8a59960ed98d-c000.snappy.parquet')),\n",
       " Row(add=None, commitInfo=None, remove=Row(dataChange=True, deletionTimestamp=1598451576335, path='part-00003-5e6f6655-260d-4c02-9539-517d20cc04c4-c000.snappy.parquet')),\n",
       " Row(add=None, commitInfo=None, remove=Row(dataChange=True, deletionTimestamp=1598451576335, path='part-00003-e1c13592-efaf-4ca7-9a0f-25484dccc18d-c000.snappy.parquet')),\n",
       " Row(add=None, commitInfo=None, remove=Row(dataChange=True, deletionTimestamp=1598451576335, path='part-00000-435ac137-7b40-43b6-98ea-f57e47b1b898-c000.snappy.parquet')),\n",
       " Row(add=None, commitInfo=None, remove=Row(dataChange=True, deletionTimestamp=1598451576335, path='part-00001-9b04da93-ebc7-46ef-88db-987405272860-c000.snappy.parquet')),\n",
       " Row(add=Row(dataChange=True, modificationTime=1598451576000, path='part-00000-97a5993f-6f5f-4d3f-b549-86652cb7a58a-c000.snappy.parquet', size=563036), commitInfo=None, remove=None),\n",
       " Row(add=Row(dataChange=True, modificationTime=1598451576000, path='part-00001-4e29cfbb-965f-44cd-a5f0-a9639435d4f8-c000.snappy.parquet', size=561764), commitInfo=None, remove=None),\n",
       " Row(add=Row(dataChange=True, modificationTime=1598451576000, path='part-00002-a69bb261-0894-4376-9a21-7b496cbc5b1b-c000.snappy.parquet', size=562089), commitInfo=None, remove=None),\n",
       " Row(add=Row(dataChange=True, modificationTime=1598451576000, path='part-00003-9b4c3093-b704-490e-a849-f970d4537a91-c000.snappy.parquet', size=558043), commitInfo=None, remove=None)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logDF = spark.read.format(\"json\").load(deltaLogPath + \"/00000000000000000011.json\")\n",
    "#dfLog.printSchema()\n",
    "logDF.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are ['28'] files.\n"
     ]
    }
   ],
   "source": [
    "# Count files in deltaPath\n",
    "\n",
    "numFiles = ! ls $deltaPath/*parquet | wc -l\n",
    "print(f\"There are {numFiles} files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+\n",
      "|ACTION|CountAction|\n",
      "+------+-----------+\n",
      "|Add   |8          |\n",
      "|Delete|16         |\n",
      "|null  |24         |\n",
      "+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "           SELECT Action, \n",
    "                  COUNT(Action) as `CountAction`\n",
    "           FROM tbl_checkpointfile \n",
    "           GROUP BY ACTION WITH ROLLUP\n",
    "          \"\"\").show(200, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delta Lake File Compaction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an artificial \"small file\" problem\n",
    "\n",
    "(spark.read\n",
    ".format(\"delta\")\n",
    ".load(deltaPath)\n",
    ".repartition(1000)\n",
    ".write\n",
    ".option(\"dataChange\", True)\n",
    ".format(\"delta\")\n",
    ".mode(\"overwrite\")\n",
    ".save(deltaPath)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are ['1028'] files.\n"
     ]
    }
   ],
   "source": [
    "# Count files in deltaPath\n",
    "\n",
    "numFiles = ! ls $deltaPath/*parquet | wc -l\n",
    "print(f\"There are {numFiles} files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Count => 4244\n",
      "\n",
      "CPU times: user 0 ns, sys: 3.56 ms, total: 3.56 ms\n",
      "Wall time: 987 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# spark.sql(\"select * from SalesDeltaFormat limit 2\").show()\n",
    "\n",
    "rowCount = spark.sql(\"\"\" SELECT CustomerID, count(Country) AS num_countries\n",
    "                         FROM SalesDeltaFormat\n",
    "                         GROUP BY CustomerID \n",
    "                     \"\"\").count()\n",
    "\n",
    "print(f\"Row Count => {rowCount}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compact 1000 files to 4\n",
    "\n",
    "(spark.read\n",
    ".format(\"delta\")\n",
    ".load(deltaPath)\n",
    ".repartition(4)\n",
    ".write\n",
    ".option(\"dataChange\", False)\n",
    ".format(\"delta\")\n",
    ".mode(\"overwrite\")\n",
    ".save(deltaPath)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are ['1032'] files.\n"
     ]
    }
   ],
   "source": [
    "# Count files in deltaPath\n",
    "\n",
    "numFiles = ! ls $deltaPath/*parquet | wc -l\n",
    "print(f\"There are {numFiles} files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Count => 4244\n",
      "CPU times: user 596 µs, sys: 3.16 ms, total: 3.76 ms\n",
      "Wall time: 255 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# spark.sql(\"select * from SalesDeltaFormat limit 2\").show()\n",
    "rowCount = spark.sql(\"\"\" select CustomerID, count(Country) as num_countries\n",
    "                         from SalesDeltaFormat\n",
    "                        group by CustomerID \"\"\").count()\n",
    "\n",
    "print(f\"Row Count => {rowCount}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delta Time Travel Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Count: 198400 as of table version 13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Time Travel Queries\n",
    "\n",
    "#POO currentVersion = deltaTable.history(1).select(\"version\").collect()[0][0]\n",
    "# Determine latest version of the Delta table\n",
    "currentVersion = spark.sql(\"DESCRIBE HISTORY SalesDeltaFormat LIMIT 1\").collect()[0][0]\n",
    "\n",
    "# Query table as of the current version to attain row count\n",
    "currentRowCount = spark.read.format(\"delta\").option(\"versionAsOf\", currentVersion).load(deltaPath).count()\n",
    "\n",
    "print(f\"Row Count: {currentRowCount} as of table version {currentVersion}\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### HISTORY ########\n",
      "+---+---------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|ver|operation|operationParameters                                                                                                                                                                               |operationMetrics                                                                                                                                                                                                       |\n",
      "+---+---------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|13 |WRITE    |[mode -> Overwrite, partitionBy -> []]                                                                                                                                                            |[numFiles -> 4, numOutputBytes -> 2968705, numOutputRows -> 198400]                                                                                                                                                    |\n",
      "|12 |WRITE    |[mode -> Overwrite, partitionBy -> []]                                                                                                                                                            |[numFiles -> 1000, numOutputBytes -> 11369812, numOutputRows -> 198400]                                                                                                                                                |\n",
      "|11 |MERGE    |[predicate -> ((spark_catalog.deltademo.SalesDeltaFormat.`StockCode` = vw_mergesalesdata.`StockCode`) AND (spark_catalog.deltademo.SalesDeltaFormat.`InvoiceNo` = vw_mergesalesdata.`InvoiceNo`))]|[numTargetRowsCopied -> 198349, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 4, numTargetRowsInserted -> 26, numTargetRowsUpdated -> 25, numOutputRows -> 198400, numSourceRows -> 46, numTargetFilesRemoved -> 8]|\n",
      "|10 |UPDATE   |[predicate -> (InvoiceNo#1116 = 560368)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 54, numCopiedRows -> 54339]                                                                                                                               |\n",
      "|9  |UPDATE   |[predicate -> (InvoiceNo#1116 = 537375)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 28, numCopiedRows -> 50093]                                                                                                                               |\n",
      "|8  |UPDATE   |[predicate -> (InvoiceNo#1116 = 546421)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 21, numCopiedRows -> 50100]                                                                                                                               |\n",
      "|7  |UPDATE   |[predicate -> (InvoiceNo#1116 = 560079)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 15, numCopiedRows -> 54378]                                                                                                                               |\n",
      "|6  |UPDATE   |[predicate -> (InvoiceNo#1116 = 560363)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 6, numCopiedRows -> 54387]                                                                                                                                |\n",
      "|5  |UPDATE   |[predicate -> (InvoiceNo#1116 = 573126)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 11, numCopiedRows -> 58914]                                                                                                                               |\n",
      "|4  |DELETE   |[predicate -> [\"(spark_catalog.deltademo.SalesDeltaFormat.`InvoiceNo` = 563202)\"]]                                                                                                                |[numRemovedFiles -> 2, numDeletedRows -> 2, numAddedFiles -> 1, numCopiedRows -> 29509]                                                                                                                                |\n",
      "|3  |UPDATE   |[predicate -> (InvoiceNo#2642 = 563202)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 2, numCopiedRows -> 29509]                                                                                                                                |\n",
      "|2  |WRITE    |[mode -> Append, partitionBy -> []]                                                                                                                                                               |[numFiles -> 1, numOutputBytes -> 2369, numOutputRows -> 1]                                                                                                                                                            |\n",
      "|1  |WRITE    |[mode -> Append, partitionBy -> []]                                                                                                                                                               |[numFiles -> 4, numOutputBytes -> 1125004, numOutputRows -> 99149]                                                                                                                                                     |\n",
      "|0  |WRITE    |[mode -> Overwrite, partitionBy -> []]                                                                                                                                                            |[numFiles -> 4, numOutputBytes -> 1129731, numOutputRows -> 99226]                                                                                                                                                     |\n",
      "+---+---------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"####### HISTORY ########\")\n",
    "\n",
    "# Observe history of actions taken on a Delta table\n",
    "history = deltaTable.history().select('version','operation', 'operationParameters', \\\n",
    "                                      'operationMetrics') \\\n",
    "                              .withColumnRenamed(\"version\", \"ver\")\n",
    "\n",
    "history.show(100, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 99174 more rows in version [13] than version [0] of the table.\n"
     ]
    }
   ],
   "source": [
    "# Determine difference in record count between the current version and the original version of the table.\n",
    "\n",
    "origRowCount = spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(deltaPath).count()\n",
    "print(f\"There are {currentRowCount-origRowCount} more rows in version [{currentVersion}] than version [0] of the table.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Roll back current table to version 0 (original).\n",
    "(\n",
    "    spark\n",
    "    .read\n",
    "    .format(\"delta\")\n",
    "    .option(\"versionAsOf\",0)\n",
    "    .load(deltaPath)\n",
    "    .write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .save(deltaPath)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Current version should have same record count as version 0.\n",
    "\n",
    "currentVersion = spark.sql(\"DESCRIBE HISTORY SalesDeltaFormat LIMIT 1\").collect()[0][0]\n",
    "# If equal it will return \"true\"\n",
    "spark.read.format(\"delta\").option(\"versionAsOf\", currentVersion).load(deltaPath).count() == spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(deltaPath).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### HISTORY ########\n",
      "+---+---------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|ver|operation|operationParameters                                                                                                                                                                               |operationMetrics                                                                                                                                                                                                       |\n",
      "+---+---------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|14 |WRITE    |[mode -> Overwrite, partitionBy -> []]                                                                                                                                                            |[numFiles -> 4, numOutputBytes -> 1129731, numOutputRows -> 99226]                                                                                                                                                     |\n",
      "|13 |WRITE    |[mode -> Overwrite, partitionBy -> []]                                                                                                                                                            |[numFiles -> 4, numOutputBytes -> 2968705, numOutputRows -> 198400]                                                                                                                                                    |\n",
      "|12 |WRITE    |[mode -> Overwrite, partitionBy -> []]                                                                                                                                                            |[numFiles -> 1000, numOutputBytes -> 11369812, numOutputRows -> 198400]                                                                                                                                                |\n",
      "|11 |MERGE    |[predicate -> ((spark_catalog.deltademo.SalesDeltaFormat.`StockCode` = vw_mergesalesdata.`StockCode`) AND (spark_catalog.deltademo.SalesDeltaFormat.`InvoiceNo` = vw_mergesalesdata.`InvoiceNo`))]|[numTargetRowsCopied -> 198349, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 4, numTargetRowsInserted -> 26, numTargetRowsUpdated -> 25, numOutputRows -> 198400, numSourceRows -> 46, numTargetFilesRemoved -> 8]|\n",
      "|10 |UPDATE   |[predicate -> (InvoiceNo#1116 = 560368)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 54, numCopiedRows -> 54339]                                                                                                                               |\n",
      "|9  |UPDATE   |[predicate -> (InvoiceNo#1116 = 537375)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 28, numCopiedRows -> 50093]                                                                                                                               |\n",
      "|8  |UPDATE   |[predicate -> (InvoiceNo#1116 = 546421)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 21, numCopiedRows -> 50100]                                                                                                                               |\n",
      "|7  |UPDATE   |[predicate -> (InvoiceNo#1116 = 560079)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 15, numCopiedRows -> 54378]                                                                                                                               |\n",
      "|6  |UPDATE   |[predicate -> (InvoiceNo#1116 = 560363)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 6, numCopiedRows -> 54387]                                                                                                                                |\n",
      "|5  |UPDATE   |[predicate -> (InvoiceNo#1116 = 573126)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 11, numCopiedRows -> 58914]                                                                                                                               |\n",
      "|4  |DELETE   |[predicate -> [\"(spark_catalog.deltademo.SalesDeltaFormat.`InvoiceNo` = 563202)\"]]                                                                                                                |[numRemovedFiles -> 2, numDeletedRows -> 2, numAddedFiles -> 1, numCopiedRows -> 29509]                                                                                                                                |\n",
      "|3  |UPDATE   |[predicate -> (InvoiceNo#2642 = 563202)]                                                                                                                                                          |[numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 2, numCopiedRows -> 29509]                                                                                                                                |\n",
      "|2  |WRITE    |[mode -> Append, partitionBy -> []]                                                                                                                                                               |[numFiles -> 1, numOutputBytes -> 2369, numOutputRows -> 1]                                                                                                                                                            |\n",
      "|1  |WRITE    |[mode -> Append, partitionBy -> []]                                                                                                                                                               |[numFiles -> 4, numOutputBytes -> 1125004, numOutputRows -> 99149]                                                                                                                                                     |\n",
      "|0  |WRITE    |[mode -> Overwrite, partitionBy -> []]                                                                                                                                                            |[numFiles -> 4, numOutputBytes -> 1129731, numOutputRows -> 99226]                                                                                                                                                     |\n",
      "+---+---------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"####### HISTORY ########\")\n",
    "\n",
    "# Observe history of actions taken on a Delta table\n",
    "history = deltaTable.history().select('version','operation', 'operationParameters', \\\n",
    "                                      'operationMetrics') \\\n",
    "                              .withColumnRenamed(\"version\", \"ver\")\n",
    "\n",
    "history.show(100, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delta Vacuum - Data Retention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "delta.logRetentionDuration - default 30 days\n",
    "<br>\n",
    "delta.deletedFileRetentionDuration - default 30 days\n",
    "\n",
    "* Don't need to set them to be the same.  You may want to keep the log files around after the tombstoned files are purged.\n",
    "* Time travel in order of months/years infeasible\n",
    "* Initially desinged to correct mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are ['1036'] files.\n"
     ]
    }
   ],
   "source": [
    "# files_in_dir(deltaPath,\"parquet\")\n",
    "# Count files in deltaPath\n",
    "\n",
    "numFiles = ! ls $deltaPath/*parquet | wc -l\n",
    "print(f\"There are {numFiles} files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "requirement failed: Are you sure you would like to vacuum files with such a low retention period? If you have\nwriters that are currently writing to this table, there is a risk that you may corrupt the\nstate of your Delta table.\n\nIf you are certain that there are no operations being performed on this table, such as\ninsert/upsert/delete/optimize, then you may turn off this check by setting:\nspark.databricks.delta.retentionDurationCheck.enabled = false\n\nIf you are not sure, please use a value not less than \"168 hours\".\n       ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-cf051bf871e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Attempt to vacuum table with default settings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"vacuum SalesDeltaFormat retain 0 hours dry run\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \"\"\"\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                 \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(e)\u001b[0m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: requirement failed: Are you sure you would like to vacuum files with such a low retention period? If you have\nwriters that are currently writing to this table, there is a risk that you may corrupt the\nstate of your Delta table.\n\nIf you are certain that there are no operations being performed on this table, such as\ninsert/upsert/delete/optimize, then you may turn off this check by setting:\nspark.databricks.delta.retentionDurationCheck.enabled = false\n\nIf you are not sure, please use a value not less than \"168 hours\".\n       "
     ]
    }
   ],
   "source": [
    "# Attempt to vacuum table with default settings\n",
    "\n",
    "spark.sql(\"vacuum SalesDeltaFormat retain 0 hours dry run\").show(100, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.databricks.delta.retentionDurationCheck.enabled\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------+\n",
      "|path                                          |\n",
      "+----------------------------------------------+\n",
      "|file:/home/spark/data/delta/online_retail_data|\n",
      "+----------------------------------------------+\n",
      "\n",
      "CPU times: user 2.54 ms, sys: 5.19 ms, total: 7.74 ms\n",
      "Wall time: 28.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Vacuum Delta table to remove all history\n",
    "\n",
    "spark.sql(\"VACUUM SalesDeltaFormat RETAIN 0 HOURS\").show(truncate = False)\n",
    "# ! Can use deltaTable.vacuum(0) against directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195KB    2020-08-26 10:26:27  part-00003-fe509e92-fde4-4a82-b9f6-64a82125c721-c000.snappy.parquet\n",
      "314KB    2020-08-26 10:26:27  part-00000-09673ae1-2d37-4bb5-af6d-195c2eb32120-c000.snappy.parquet\n",
      "282KB    2020-08-26 10:26:27  part-00002-9a16b75f-9563-412c-8f74-6b3ffef17e9e-c000.snappy.parquet\n",
      "312KB    2020-08-26 10:26:27  part-00001-9b64e2c8-dcdd-468a-856b-60d9349cc370-c000.snappy.parquet\n",
      "\n",
      "Number of file/s: 4 | Total size: 1.6M\n"
     ]
    }
   ],
   "source": [
    "files_in_dir(deltaPath,\"parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2KB      2020-08-26 10:13:04  00000000000000000000.json\n",
      "938B     2020-08-26 10:14:14  00000000000000000001.json\n",
      "410B     2020-08-26 10:14:59  00000000000000000002.json\n",
      "902B     2020-08-26 10:15:18  00000000000000000003.json\n",
      "775B     2020-08-26 10:16:31  00000000000000000004.json\n",
      "905B     2020-08-26 10:17:59  00000000000000000005.json\n",
      "904B     2020-08-26 10:18:00  00000000000000000006.json\n",
      "905B     2020-08-26 10:18:02  00000000000000000007.json\n",
      "905B     2020-08-26 10:18:04  00000000000000000008.json\n",
      "905B     2020-08-26 10:18:05  00000000000000000009.json\n",
      "905B     2020-08-26 10:18:07  00000000000000000010.json\n",
      "17KB     2020-08-26 10:18:08  00000000000000000010.checkpoint.parquet\n",
      "2KB      2020-08-26 10:19:36  00000000000000000011.json\n",
      "169KB    2020-08-26 10:25:15  00000000000000000012.json\n",
      "141KB    2020-08-26 10:25:35  00000000000000000013.json\n",
      "2KB      2020-08-26 10:26:28  00000000000000000014.json\n",
      "\n",
      "Number of file/s: 16 | Total size: 400K\n"
     ]
    }
   ],
   "source": [
    "files_in_dir(deltaLogPath,\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(add=None, commitInfo=Row(isBlindAppend=False, operation='WRITE', operationMetrics=Row(numFiles='4', numOutputBytes='1129731', numOutputRows='99226'), operationParameters=Row(mode='Overwrite', partitionBy='[]'), readVersion=13, timestamp=1598451987996, userMetadata='08-25-2020 Data Merge;'), remove=None),\n",
       " Row(add=Row(dataChange=True, modificationTime=1598451987000, path='part-00000-09673ae1-2d37-4bb5-af6d-195c2eb32120-c000.snappy.parquet', size=321712), commitInfo=None, remove=None),\n",
       " Row(add=Row(dataChange=True, modificationTime=1598451987000, path='part-00001-9b64e2c8-dcdd-468a-856b-60d9349cc370-c000.snappy.parquet', size=319754), commitInfo=None, remove=None),\n",
       " Row(add=Row(dataChange=True, modificationTime=1598451987000, path='part-00002-9a16b75f-9563-412c-8f74-6b3ffef17e9e-c000.snappy.parquet', size=288465), commitInfo=None, remove=None),\n",
       " Row(add=Row(dataChange=True, modificationTime=1598451987000, path='part-00003-fe509e92-fde4-4a82-b9f6-64a82125c721-c000.snappy.parquet', size=199800), commitInfo=None, remove=None),\n",
       " Row(add=None, commitInfo=None, remove=Row(dataChange=True, deletionTimestamp=1598451987996, path='part-00001-c55a0153-a6a4-43e0-9932-5cdd7a029073-c000.snappy.parquet')),\n",
       " Row(add=None, commitInfo=None, remove=Row(dataChange=True, deletionTimestamp=1598451987996, path='part-00003-052fb3c1-d663-4866-968a-e4fdb43e2efb-c000.snappy.parquet')),\n",
       " Row(add=None, commitInfo=None, remove=Row(dataChange=True, deletionTimestamp=1598451987996, path='part-00002-ab31b8ee-7899-4dc1-b619-fbe1bc559ab8-c000.snappy.parquet')),\n",
       " Row(add=None, commitInfo=None, remove=Row(dataChange=True, deletionTimestamp=1598451987996, path='part-00000-ca52a6d2-cc73-4812-a2c4-883bddd34c51-c000.snappy.parquet'))]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.format(\"json\").load(deltaLogPath + \"/00000000000000000014.json\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99226"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.format(\"delta\").option(\"versionAsOf\", currentVersion).load(deltaPath).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure Delta table to keep around 7 days of deleted data and 7 days of older log files\n",
    "spark.sql(\"alter table SalesDeltaFormat set tblproperties ('delta.logRetentionDuration' = 'interval 7 days', 'delta.deletedFileRetentionDuration' = 'interval 7 days')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+-----------------------------------------------------------------------------------------------+-------+\n",
      "|col_name                    |data_type                                                                                      |comment|\n",
      "+----------------------------+-----------------------------------------------------------------------------------------------+-------+\n",
      "|InvoiceNo                   |int                                                                                            |       |\n",
      "|StockCode                   |string                                                                                         |       |\n",
      "|Description                 |string                                                                                         |       |\n",
      "|Quantity                    |int                                                                                            |       |\n",
      "|InvoiceDate                 |string                                                                                         |       |\n",
      "|UnitPrice                   |double                                                                                         |       |\n",
      "|CustomerID                  |int                                                                                            |       |\n",
      "|Country                     |string                                                                                         |       |\n",
      "|                            |                                                                                               |       |\n",
      "|# Partitioning              |                                                                                               |       |\n",
      "|Not partitioned             |                                                                                               |       |\n",
      "|                            |                                                                                               |       |\n",
      "|# Detailed Table Information|                                                                                               |       |\n",
      "|Name                        |deltademo.salesdeltaformat                                                                     |       |\n",
      "|Location                    |file:/home/spark/data/delta/online_retail_data                                                 |       |\n",
      "|Provider                    |delta                                                                                          |       |\n",
      "|Table Properties            |[delta.deletedFileRetentionDuration=interval 7 days,delta.logRetentionDuration=interval 7 days]|       |\n",
      "+----------------------------+-----------------------------------------------------------------------------------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verify our changes\n",
    "spark.sql(\"describe extended SalesDeltaFormat\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
